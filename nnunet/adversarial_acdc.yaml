model: 'swin' #'swin'
separability: False
separability_loss_weight: 1.0
convolutional_patch_embedding: True

middle_loss_weight: 1.0
seg_motion_estimation_loss_weight: 0.1
alpha_ema: 0.01
middle_classification: False
middle_classification_weight: 0.1
one_vs_all: True
maximize_distance: False
average_distance: False
similarity_loss_weight: 10.0 #100.0
#contrastive_loss_weight: 100.0
mix_residual: True
registered_seg: True
nb_repeat: 4 #4, 2
middle_unlabeled: False
t1: 0.1
t2: 0.5
max_unlabeled_weight: 1
v1: True

log_images: True
transformer_bottleneck: True
device: 'cuda:0'
simple_decoder: False
deep_supervision: True
add_extra_bottleneck_blocks: True
affinity: False
affinity_loss_weight: 0.0001 # 0.001
unlabeled_loss_weight: 2
unlabeled: False
progressive_similarity_growing: False
classification_weight: 0.1 #1.45
classification: False
similarity: False
asymmetric_unet: True
epoch_log: 10 #10
scheduler: 'cosine'
optimizer: 'adam'
adversarial_loss: False
alpha_discriminator: 0.10 #0.125
adversarial_weight: 1.0 #0.1
discriminator_lr: 0.00001 # 0.00005
initial_lr: 0.0001 #0.0001
discriminator_decay: 0.0001
weight_decay: 0.0001 #0.0001
warmup_percent: 0.1
smoothing: 0.0
max_num_epochs: 1000 #1000
patch_size: [224, 224] # dynamic_mri=288, quorum=288
norm: 'BatchNorm2d' # 'InstanceNorm2d', 'BatchNorm2d', ''
filter_skip_co_reconstruction: False
filter_skip_co_segmentation: True
bottleneck_heads: 8 # 16
dim_feedforward: 3072
activation: 'gelu'
conv_layer: 'other'
num_bottleneck_layers: 1
dropout: 0
conv_depth: [2, 2, 2]
transformer_depth: [] #[2, 2, 2], [2]
num_heads: [] #[3, 6, 12], [8] [12]
spatial_cross_attention_num_heads: [2, 4, 8] #[2, 4, 6, 8, 12] [12, 8, 6, 4, 2] [bottom, ..., top] [3, 6, 12] [4, 4, 8, 8, 16]
batch_size: 1 #6
bottleneck: 'swin' # ['vit', 'swin', 'factorized', 'vit_3d', 'swin_3d']
rpe_mode: 'bias' # ['contextual', 'bias', 'None']
rpe_contextual_tensors: 'qkv'
drop_path_rate: 0.0
autoencoder_dim: 64
in_encoder_dims: [1, 128, 256] #[1, 24, 96, 192, 384] [1, 96, 384] [1, 24, 96] [1, 32, 128] [1, 32, 128, 256, 512] [1, 48, 192] [1, 96, 192]
out_encoder_dims: [64, 128, 256] #[24, 48, 96, 192, 384] [96, 192, 384] [24, 48, 96] [32, 64, 128] [32, 64, 128, 256, 512] [48, 96, 192] [96, 192, 384]
merge: 'linear' # ['linear', 'rescale_linear', 'rescale_conv']
zoom_p: 0.25
rotation_p: 0.25
shear_p: 0.0
translate_p: 0.25
flipv_p: 0.0
fliph_p: 0.0
sharp_p: 0.25
noise_p: 0.25
gamma_p: 0.25
mixup_p: 0.0
cutmix_p: 0.0
cowmix_p: 0.0
elastic_p: 0.25
brightness_p: 0.25
my_augmentation_p: 0.0
rotation_degree: [-45, 45] # [-90, 45]
elastic_std: 5.0
zoom_scale: [0.7, 1.3]
shear_range: [20.0, 20.0] # angle
translate_scale: [5.0, 5.0] # pixels [5.0, 5.0]
sharp_range: [0.0, 2.0]
brightness_range: [0.7, 1.2]
std_noise: 0.01
gamma_range: [0.7, 1.3]
cowmix_sigma_range: [3.0, 5.0]
cowmix_proportion_range: [0.5, 0.7]
cowmix_kernel_size: 15.0
lambda_start: 0.01
lambda_end: 0.99
spatial_transformer_loss: 'focal_and_dice'
loss: 'ce_and_dice' # ['ce_and_dice', 'focal_and_dice', 'topk_and_dice', 'ce']
unlabeled_loss: 'focal_and_dice' # ['dice', 'dice_and_boundary', 'dice_and_perimeter', 'generalized_dice', 'cross_entropy', 'generalized_dice_and_boundary', 'cross_entropy', 'topk_and_dice', 'topk_and_generalized_dice', 'focal_and_dice', 'focal_and_generalized_dice']
semi_supervised: False
topk_percent: 0.1
unlabeled_loss_weight_start: 0.0
unlabeled_loss_weight_end: 1.0
swin_abs_pos: False
load_weights: False
blur: False
blur_kernel: [1, 2, 1]
use_spatial_transformer: False
localization_weight: 1
mlp_intermediary_dim: 256
use_conv_mlp: True
proj: 'linear' # 'linear', 'conv'
plot_gradient_iter_number: 100000000000
shortcut: False
encoder_attention_type: [] #['channel', 'spatial', 'identity']
reconstruction_attention_type: [] #['channel', 'spatial', 'identity']
concat_spatial_cross_attention: True
directional_field: False
directional_field_weight: 1.0

learn_transforms: False
use_cropped_images: True

reconstruction: False
reconstruction_skip: False
reconstruction_loss_weight: 1.0 #2.65
similarity_weight: 0.1 #0.0001
similarity_down_scale: 8
uncertainty_weighting: False
dynamic_weight_averaging: False

rotation_loss_weight: 0.3
scaling_loss_weight: 0.3
reconstruction_rotation_loss_weight: 0.001
reconstruction_scaling_loss_weight: 0.001
target_ratio: 0.15

adversarial: False
image_or_label: 'image'
discriminator_depth: [2, 2, 2]
seg_in_discriminator_dims: [5, 64, 128]
rec_in_discriminator_dims: [1, 64, 128]
out_discriminator_dims: [64, 128, 256]
discriminator_learning_rate: 0.0005
discriminator_weight_decay: 0.0001
r1_penalty_iteration: 1
adversarial_loss_weight: 1.0

reinforcement: False
policy_net_learning_rate: 0.0001
number_of_intervals: 20
number_of_steps: 200

nb_nets: 1

second_conv_depth: [4, 4]
second_transformer_depth: [2] #[2, 2, 2], [2]
second_num_heads: [8] #[3, 6, 12], [8]
second_in_dims: [1, 48, 192] #[1, 24, 96, 192, 384] [1, 96, 384] [1, 24, 96] [1, 32, 128]
second_bottleneck_heads: 16
second_net_loss_weight: 1.0

third_conv_depth: [4, 4]
third_transformer_depth: [2] #[2, 2, 2], [2]
third_num_heads: [8] #[3, 6, 12], [8]
third_in_dims: [1, 48, 192] #[1, 24, 96, 192, 384] [1, 96, 384] [1, 24, 96] [1, 32, 128]
third_bottleneck_heads: 16
third_net_loss_weight: 1.0

loss_weights_binary: [0.0404778230051879, 0.959522176994812]

small: False
loss_weights_small: [0.02750239033581403, 0.6297990114118536, 0.1266837091920396, 0.21601488906029276]

big: False
loss_weights_big: [0.009622007580133, 0.34223122737765677, 0.32055540070262845, 0.3275913643395818]

binary_resampled_loss_weights: [0.059967399088541644, 0.9400326009114582] # 224 = [0.03060070219494048, 0.9693992978050595]
224_loss_weights: [0.0066582237764044325, 0.3385361280090397, 0.327149629210459, 0.32765601900409697]
160_loss_weights: [0.009092481157748094, 0.33804275090754565, 0.3261811949429598, 0.32668357299174644]
160_binary_loss_weights: [0.07630263784831759, 0.9236973621516824]
128_loss_weights: [0.014816022021090905, 0.3359826005495696, 0.3243509091758728, 0.32485046825346664]
128_loss_weights_125: [0.022908228964674742, 0.3329980403455186, 0.32179781244481237, 0.3222959182449944]
128_transformed_loss_weights: [0.018200049361858688, 0.38031857478585657, 0.2682702694739415, 0.3332111063783432]
352_loss_weights: [0.0026134481559843305, 0.33991460892062303, 0.3284817455838297, 0.32899019733956303]
compute_overfitting: False
attention_map: False
