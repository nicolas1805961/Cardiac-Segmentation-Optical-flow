{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get results by criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "output_file_name = 'quorum_output_field.yaml'\n",
    "if os.path.exists(output_file_name):\n",
    "    os.remove(output_file_name)\n",
    "\n",
    "centers = {}\n",
    "manufacturers = {}\n",
    "strengths = {}\n",
    "depths = {}\n",
    "phases = {}\n",
    "\n",
    "path_list = glob(r'quorum_output_2\\fold_0\\temp_allClasses\\*.gz')\n",
    "for path in path_list:\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    name = filename.split('_')[0]\n",
    "    df = pd.read_csv(os.path.join('custom_quorum_2', name, phase + '_info.csv'))\n",
    "    center = df['Name'].iloc[0].split('-')[0]\n",
    "    manufacturer = df['Manufacturer'].iloc[0]\n",
    "    strength = df['Field Strength'].iloc[0]\n",
    "\n",
    "    centers = update_dict(centers, str(center), filename)\n",
    "    manufacturers = update_dict(manufacturers, str(manufacturer), filename)\n",
    "    strengths = update_dict(strengths, str(strength), filename)\n",
    "    phases = update_dict(phases, str(phase), filename)\n",
    "\n",
    "with open(r'quorum_output_2\\fold_0\\temp_allClasses\\summary.json', 'r') as fd_in:\n",
    "    metric_file = json.load(fd_in)['results']['all']\n",
    "    results_dict = {}\n",
    "    for current_dict in [centers, manufacturers, strengths, phases]:\n",
    "        for key in current_dict.keys():\n",
    "            current_values = current_dict[key]\n",
    "            list_of_dict = [x for x in metric_file if x['reference'].split('/')[-1] in current_values]\n",
    "            mean_dice_list = []\n",
    "            mean_hausdorff_list = []\n",
    "            for data_dict in list_of_dict:\n",
    "                mean_dice_list.append([data_dict['1']['Dice'], data_dict['2']['Dice'], data_dict['3']['Dice']])\n",
    "                mean_hausdorff_list.append([data_dict['1']['Hausdorff Distance'], data_dict['2']['Hausdorff Distance'], data_dict['3']['Hausdorff Distance']])\n",
    "            class_dice = np.stack(mean_dice_list, axis=0).mean(axis=0)\n",
    "            class_hausdorff = np.stack(mean_hausdorff_list, axis=0).mean(axis=0)\n",
    "            results_dict[key] = {'Hausdorff distance': class_hausdorff.tolist(), \n",
    "                                'Mean Hausdorff distance': float(class_hausdorff.mean()), \n",
    "                                'Dice score': class_dice.tolist(),\n",
    "                                'Mean dice score': float(class_dice.mean())}\n",
    "\n",
    "with open(output_file_name, 'w') as fd:\n",
    "    yaml.safe_dump(results_dict, fd, default_flow_style=False)\n",
    "    #for results_dict in results_dicts:\n",
    "    #    for key in results_dict.keys():\n",
    "    #        fd.write(key + ': ' + str(results_dict[key]) + '\\n')\n",
    "    #    fd.write('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ED/ES volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.234375\n",
      "187504.625\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "data = nib.load(r'quorum_output\\validation_raw\\patient003_ed.nii.gz')\n",
    "zoom = data.header.get_zooms()\n",
    "pixel_volume = np.prod(zoom)\n",
    "print(pixel_volume)\n",
    "arr = data.get_fdata()\n",
    "nb_pixels = np.count_nonzero(arr == 1)\n",
    "print(nb_pixels * pixel_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 288, 13)\n",
      "(288, 288, 14)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.interpolate import interpn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bwperim(bw, n=4):\n",
    "    \"\"\"\n",
    "    perim = bwperim(bw, n=4)\n",
    "    Find the perimeter of objects in binary images.\n",
    "    A pixel is part of an object perimeter if its value is one and there\n",
    "    is at least one zero-valued pixel in its neighborhood.\n",
    "    By default the neighborhood of a pixel is 4 nearest pixels, but\n",
    "    if `n` is set to 8 the 8 nearest pixels will be considered.\n",
    "    Parameters\n",
    "    ----------\n",
    "      bw : A black-and-white image\n",
    "      n : Connectivity. Must be 4 or 8 (default: 8)\n",
    "    Returns\n",
    "    -------\n",
    "      perim : A boolean image\n",
    "    \"\"\"\n",
    "\n",
    "    if n not in (4,8):\n",
    "        raise ValueError('mahotas.bwperim: n must be 4 or 8')\n",
    "    rows,cols = bw.shape\n",
    "\n",
    "    # Translate image by one pixel in all directions\n",
    "    north = np.zeros((rows,cols))\n",
    "    south = np.zeros((rows,cols))\n",
    "    west = np.zeros((rows,cols))\n",
    "    east = np.zeros((rows,cols))\n",
    "\n",
    "    north[:-1,:] = bw[1:,:]\n",
    "    south[1:,:]  = bw[:-1,:]\n",
    "    west[:,:-1]  = bw[:,1:]\n",
    "    east[:,1:]   = bw[:,:-1]\n",
    "    idx = (north == bw) & \\\n",
    "          (south == bw) & \\\n",
    "          (west  == bw) & \\\n",
    "          (east  == bw)\n",
    "    if n == 8:\n",
    "        north_east = np.zeros((rows, cols))\n",
    "        north_west = np.zeros((rows, cols))\n",
    "        south_east = np.zeros((rows, cols))\n",
    "        south_west = np.zeros((rows, cols))\n",
    "        north_east[:-1, 1:]   = bw[1:, :-1]\n",
    "        north_west[:-1, :-1] = bw[1:, 1:]\n",
    "        south_east[1:, 1:]     = bw[:-1, :-1]\n",
    "        south_west[1:, :-1]   = bw[:-1, 1:]\n",
    "        idx &= (north_east == bw) & \\\n",
    "               (south_east == bw) & \\\n",
    "               (south_west == bw) & \\\n",
    "               (north_west == bw)\n",
    "    return ~idx * bw\n",
    "\n",
    "def signed_bwdist(im):\n",
    "    '''\n",
    "    Find perim and return masked image (signed/reversed)\n",
    "    '''    \n",
    "    perimeter = bwperim(im)\n",
    "    distance_map = bwdist(perimeter)\n",
    "    im = -distance_map*np.logical_not(im) + distance_map*im\n",
    "    return im\n",
    "\n",
    "def bwdist(im):\n",
    "    '''\n",
    "    Find distance map of image\n",
    "    '''\n",
    "    dist_im = distance_transform_edt(1-im)\n",
    "    return dist_im\n",
    "\n",
    "def interp_shape(arr, new_depth):\n",
    "    '''\n",
    "    Interpolate between two contours\n",
    "\n",
    "    Input: top \n",
    "            [X,Y] - Image of top contour (mask)\n",
    "           bottom\n",
    "            [X,Y] - Image of bottom contour (mask)\n",
    "           precision\n",
    "             float  - % between the images to interpolate \n",
    "                Ex: num=0.5 - Interpolate the middle image between top and bottom image\n",
    "    Output: out\n",
    "            [X,Y] - Interpolated image at num (%) between top and bottom\n",
    "\n",
    "    '''\n",
    "    X, Y, Z = arr.shape\n",
    "\n",
    "    distance_arr = []\n",
    "    for i in range(Z):\n",
    "        distance_arr.append(signed_bwdist(arr[:, :, i]))\n",
    "    distance_arr = np.stack(distance_arr, axis=-1)\n",
    "\n",
    "    x = np.arange(0, X)\n",
    "    y = np.arange(0, Y)\n",
    "    z = np.arange(0, Z)\n",
    "    points = (x, y, z)\n",
    "\n",
    "    stop = Z-1\n",
    "\n",
    "    # create ndgrids\n",
    "    grid = np.mgrid[:X, :Y, 0:stop:(new_depth * 1j)]\n",
    "    xi = np.rollaxis(grid, 0, 4)\n",
    "    xi = xi.reshape((X * Y * new_depth, 3))\n",
    "\n",
    "    out = interpn(points, arr, xi)\n",
    "    out = out.reshape((X, Y, new_depth))\n",
    "\n",
    "    # Threshold distmap to values above 0\n",
    "    out = out > 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "data = nib.load(r'quorum_output\\validation_raw\\patient003_ed.nii.gz')\n",
    "arr = data.get_fdata()\n",
    "arr = arr == 1\n",
    "\n",
    "X, Y, Z = arr.shape\n",
    "print(arr.shape)\n",
    "# Run interpolation\n",
    "out = interp_shape(arr, Z+1)\n",
    "print(out.shape)\n",
    "#fig, ax = plt.subplots(1, Z+1)\n",
    "#for i in range(Z+1):\n",
    "#    ax[i].imshow(out[:, :, i], cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only patient in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "\n",
    "cut_prediction_path = r'quorum_output_2\\fold_0\\temp_allClasses'\n",
    "all_prediction_path = r'data_saud_2\\inference'\n",
    "\n",
    "data_dict_cut = {}\n",
    "data_dict_all = {}\n",
    "\n",
    "path_list = glob(os.path.join(cut_prediction_path, '*.gz'))\n",
    "cut_prediction_names = []\n",
    "for path in path_list:\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    name = filename.split('_')[0]\n",
    "    df = pd.read_csv(os.path.join('custom_quorum_2', name, phase + '_info.csv'))\n",
    "    actual_name = df['Name'].to_numpy()[0]\n",
    "    spacing = (df['Space Between Slices'] - df['Slice Thickness']).to_numpy()[0]\n",
    "    cut_prediction_names.append(actual_name)\n",
    "    if phase == 'ed':\n",
    "        update_dict(data_dict_cut, 'ed', (path, spacing))\n",
    "    elif phase == 'es':\n",
    "        update_dict(data_dict_cut, 'es', (path, spacing))\n",
    "\n",
    "csv_list = glob(os.path.join(all_prediction_path, '*.csv'))\n",
    "for csv_path in csv_list:\n",
    "    filename = csv_path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    df = pd.read_csv(csv_path)\n",
    "    actual_name = df['Name'].to_numpy()[0]\n",
    "    if actual_name in cut_prediction_names:\n",
    "        spacing = (df['Space Between Slices'] - df['Slice Thickness']).to_numpy()[0]\n",
    "        path = csv_path[:-4] + '.nii.gz'\n",
    "        if phase == 'ed':\n",
    "            update_dict(data_dict_all, 'ed', (path, spacing))\n",
    "        elif phase == 'es':\n",
    "            update_dict(data_dict_all, 'es', (path, spacing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "d.setdefault()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RV': {'ed': {'volume': 114.4681600737512, 'interpolated_volume': 118.36219308819175}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:29<00:58, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RV': {'ed': {'volume': 114.4681600737512, 'interpolated_volume': 118.36219308819175}, 'es': {'volume': 55.430812819492814, 'interpolated_volume': 57.48326070774793}}}\n",
      "{'RV': {'ed': {'volume': 114.4681600737512, 'interpolated_volume': 118.36219308819175}, 'es': {'volume': 55.430812819492814, 'interpolated_volume': 57.48326070774793}, \"Fraction d'ejection\": {'no_interpolation': 51.57534393513529, 'interpolated': 51.434441008610655}, \"Volume d'ejection\": {'no_interpolation': 59.03734725425839, 'interpolated': 60.878932380443814}}, 'MYO': {'ed': {'volume': 120.73369108983277, 'interpolated_volume': 125.95945888906718}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:58<00:29, 29.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RV': {'ed': {'volume': 114.4681600737512, 'interpolated_volume': 118.36219308819175}, 'es': {'volume': 55.430812819492814, 'interpolated_volume': 57.48326070774793}, \"Fraction d'ejection\": {'no_interpolation': 51.57534393513529, 'interpolated': 51.434441008610655}, \"Volume d'ejection\": {'no_interpolation': 59.03734725425839, 'interpolated': 60.878932380443814}}, 'MYO': {'ed': {'volume': 120.73369108983277, 'interpolated_volume': 125.95945888906718}, 'es': {'volume': 121.01181117264628, 'interpolated_volume': 125.88918936514258}}}\n",
      "{'RV': {'ed': {'volume': 114.4681600737512, 'interpolated_volume': 118.36219308819175}, 'es': {'volume': 55.430812819492814, 'interpolated_volume': 57.48326070774793}, \"Fraction d'ejection\": {'no_interpolation': 51.57534393513529, 'interpolated': 51.434441008610655}, \"Volume d'ejection\": {'no_interpolation': 59.03734725425839, 'interpolated': 60.878932380443814}}, 'MYO': {'ed': {'volume': 120.73369108983277, 'interpolated_volume': 125.95945888906718}, 'es': {'volume': 121.01181117264628, 'interpolated_volume': 125.88918936514258}}, 'LV': {'ed': {'volume': 130.12948671207428, 'interpolated_volume': 133.7035809165001}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:27<00:00, 29.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RV': {'ed': {'volume': 114.4681600737512, 'interpolated_volume': 118.36219308819175}, 'es': {'volume': 55.430812819492814, 'interpolated_volume': 57.48326070774793}, \"Fraction d'ejection\": {'no_interpolation': 51.57534393513529, 'interpolated': 51.434441008610655}, \"Volume d'ejection\": {'no_interpolation': 59.03734725425839, 'interpolated': 60.878932380443814}}, 'MYO': {'ed': {'volume': 120.73369108983277, 'interpolated_volume': 125.95945888906718}, 'es': {'volume': 121.01181117264628, 'interpolated_volume': 125.88918936514258}}, 'LV': {'ed': {'volume': 130.12948671207428, 'interpolated_volume': 133.7035809165001}, 'es': {'volume': 70.84893249348998, 'interpolated_volume': 73.0117169892013}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RV': {'ed': {'volume': 145.82902176328898, 'interpolated_volume': 150.4830108797431}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:38<01:16, 38.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RV': {'ed': {'volume': 145.82902176328898, 'interpolated_volume': 150.4830108797431}, 'es': {'volume': 96.67762180504202, 'interpolated_volume': 100.31756444570422}}}\n",
      "{'RV': {'ed': {'volume': 145.82902176328898, 'interpolated_volume': 150.4830108797431}, 'es': {'volume': 96.67762180504202, 'interpolated_volume': 100.31756444570422}, \"Fraction d'ejection\": {'no_interpolation': 33.70481359878417, 'interpolated': 33.336285698143065}, \"Volume d'ejection\": {'no_interpolation': 49.151399958246955, 'interpolated': 50.16544643403887}}, 'MYO': {'ed': {'volume': 142.07228779793383, 'interpolated_volume': 147.87926809695364}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [01:16<00:38, 38.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RV': {'ed': {'volume': 145.82902176328898, 'interpolated_volume': 150.4830108797431}, 'es': {'volume': 96.67762180504202, 'interpolated_volume': 100.31756444570422}, \"Fraction d'ejection\": {'no_interpolation': 33.70481359878417, 'interpolated': 33.336285698143065}, \"Volume d'ejection\": {'no_interpolation': 49.151399958246955, 'interpolated': 50.16544643403887}}, 'MYO': {'ed': {'volume': 142.07228779793383, 'interpolated_volume': 147.87926809695364}, 'es': {'volume': 156.49667739224435, 'interpolated_volume': 162.14413649783134}}}\n",
      "{'RV': {'ed': {'volume': 145.82902176328898, 'interpolated_volume': 150.4830108797431}, 'es': {'volume': 96.67762180504202, 'interpolated_volume': 100.31756444570422}, \"Fraction d'ejection\": {'no_interpolation': 33.70481359878417, 'interpolated': 33.336285698143065}, \"Volume d'ejection\": {'no_interpolation': 49.151399958246955, 'interpolated': 50.16544643403887}}, 'MYO': {'ed': {'volume': 142.07228779793383, 'interpolated_volume': 147.87926809695364}, 'es': {'volume': 156.49667739224435, 'interpolated_volume': 162.14413649783134}}, 'LV': {'ed': {'volume': 153.7015105767846, 'interpolated_volume': 157.47729249504806}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:55<00:00, 38.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'RV': {'ed': {'volume': 145.82902176328898, 'interpolated_volume': 150.4830108797431}, 'es': {'volume': 96.67762180504202, 'interpolated_volume': 100.31756444570422}, \"Fraction d'ejection\": {'no_interpolation': 33.70481359878417, 'interpolated': 33.336285698143065}, \"Volume d'ejection\": {'no_interpolation': 49.151399958246955, 'interpolated': 50.16544643403887}}, 'MYO': {'ed': {'volume': 142.07228779793383, 'interpolated_volume': 147.87926809695364}, 'es': {'volume': 156.49667739224435, 'interpolated_volume': 162.14413649783134}}, 'LV': {'ed': {'volume': 153.7015105767846, 'interpolated_volume': 157.47729249504806}, 'es': {'volume': 95.7465147231102, 'interpolated_volume': 98.32257042517662}}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "#path_list = glob(r'quorum_output_2\\temp_allClasses\\*.gz')\n",
    "\n",
    "for data_dict, output_file_name in zip([data_dict_cut, data_dict_all], ['quorum_output_volume_cut.yaml', 'quorum_output_volume_all.yaml']):\n",
    "    if os.path.exists(output_file_name):\n",
    "        os.remove(output_file_name)\n",
    "    results = {}\n",
    "    for i, class_name in enumerate(tqdm(['RV', 'MYO', 'LV']), 1):\n",
    "        phase_results = {}\n",
    "        for phase in data_dict.keys():\n",
    "            volume_list = []\n",
    "            volume_list_interp = []\n",
    "            list_of_tuple = data_dict[phase]\n",
    "            for path, spacing in list_of_tuple:\n",
    "                data = nib.load(path)\n",
    "                zoom = list(data.header.get_zooms())\n",
    "                arr = data.get_fdata()\n",
    "                pixel_size = np.prod(zoom)\n",
    "\n",
    "                new_depth = round((spacing * (arr.shape[-1] - 1)) / zoom[-1]) + arr.shape[-1]\n",
    "                #print(arr.shape[-1])\n",
    "                #print(new_depth)\n",
    "                #print('******************************')\n",
    "\n",
    "                class_nb_pixels = arr == i\n",
    "\n",
    "                arr_interpolated = interp_shape(class_nb_pixels, new_depth)\n",
    "                volume_no_interp = pixel_size * class_nb_pixels.sum()\n",
    "                volume_interp = pixel_size * arr_interpolated.sum()\n",
    "                volume_list.append(volume_no_interp)\n",
    "                volume_list_interp.append(volume_interp)\n",
    "\n",
    "            mean_volume = float(np.array(volume_list).mean() / 1000)\n",
    "            mean_volume_interp = float(np.array(volume_list_interp).mean() / 1000)\n",
    "            res = {'volume': mean_volume, 'interpolated_volume': mean_volume_interp}\n",
    "            phase_results.setdefault(phase, res)\n",
    "            results.setdefault(class_name, phase_results)\n",
    "            print(results)\n",
    "        if class_name != 'MYO':\n",
    "            results[class_name].update({\n",
    "                'Fraction d\\'ejection': {'no_interpolation': ((results[class_name]['ed']['volume'] - results[class_name]['es']['volume']) / results[class_name]['ed']['volume']) * 100,\n",
    "                                        'interpolated': ((results[class_name]['ed']['interpolated_volume'] - results[class_name]['es']['interpolated_volume']) / results[class_name]['ed']['interpolated_volume']) * 100},\n",
    "                'Volume d\\'ejection': {'no_interpolation': (results[class_name]['ed']['volume'] - results[class_name]['es']['volume']),\n",
    "                                        'interpolated': (results[class_name]['ed']['interpolated_volume'] - results[class_name]['es']['interpolated_volume'])}\n",
    "                                        })          \n",
    "\n",
    "    with open(output_file_name, 'w') as fd:\n",
    "        yaml.safe_dump(results, fd, default_flow_style=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dice per depth level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.metrics import dice\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "path_list = glob(r'quorum_output_2\\fold_0\\temp_allClasses\\*.gz')\n",
    "path_list_names = [x.split('\\\\')[-1][:13] for x in path_list]\n",
    "path_list_gt = glob(r'custom_quorum_2\\**\\*_gt.nii.gz', recursive=True)\n",
    "path_list_gt = [x for x in path_list_gt if x.split('\\\\')[-1][:13] in path_list_names]\n",
    "assert len(path_list_gt) == len(path_list)\n",
    "\n",
    "path_list = sorted(path_list, key=lambda x:x.split('\\\\')[-1])\n",
    "path_list_gt = sorted(path_list_gt, key=lambda x:x.split('\\\\')[-1])\n",
    "\n",
    "out_dict = {}\n",
    "for path, path_gt in zip(path_list, path_list_gt):\n",
    "    data = nib.load(path)\n",
    "    arr = data.get_fdata()\n",
    "\n",
    "    data_gt = nib.load(path_gt)\n",
    "    arr_gt = data_gt.get_fdata()\n",
    "\n",
    "    assert arr.shape == arr_gt.shape\n",
    "    for i in range(arr.shape[-1]):\n",
    "        #fig, ax = plt.subplots(1, 2)\n",
    "        #ax[0].imshow(arr[:, :, i], cmap='gray')\n",
    "        #ax[1].imshow(arr_gt[:, :, i], cmap='gray')\n",
    "        #plt.show()\n",
    "        #plt.waitforbuttonpress()\n",
    "        #plt.close(fig)\n",
    "        score = dice(test=arr[:, :, i], reference=arr_gt[:, :, i])\n",
    "        out_dict = update_dict(out_dict, key=i/arr.shape[-1], value=score)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for key in out_dict.keys():\n",
    "    x.append(key)\n",
    "    y.append(np.array(out_dict[key]).mean())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(np.array(x), np.array(y))\n",
    "ax.set(xlabel='Depth as percent of volume', ylabel='Dice score')\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de6e7f1d27ee98e0dd03d720850162ba8f013030d5557c31bd8d79f8fd588abc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
