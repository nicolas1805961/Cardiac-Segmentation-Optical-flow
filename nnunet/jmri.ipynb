{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get results by criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250001 = 10\n",
      "250005 = 2\n",
      "276004 = 2\n",
      "276005 = 2\n",
      "276008 = 2\n",
      "348001 = 6\n",
      "348002 = 6\n",
      "348003 = 2\n",
      "348004 = 8\n",
      "348007 = 6\n",
      "616003 = 4\n",
      "616005 = 2\n",
      "616010 = 2\n",
      "703001 = 10\n",
      "703003 = 2\n",
      "703004 = 8\n",
      "724002 = 2\n",
      "724006 = 4\n",
      "siemens = 62\n",
      "philips = 4\n",
      "ge = 14\n",
      "1.5 = 66\n",
      "3.0 = 14\n",
      "ed = 40\n",
      "es = 40\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "output_file_name = 'quorum_output_field.yaml'\n",
    "if os.path.exists(output_file_name):\n",
    "    os.remove(output_file_name)\n",
    "\n",
    "centers = {}\n",
    "manufacturers = {}\n",
    "strengths = {}\n",
    "depths = {}\n",
    "phases = {}\n",
    "\n",
    "path_list = glob(r'quorum_output_2\\fold_0\\temp_allClasses\\*.gz')\n",
    "for path in path_list:\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    name = filename.split('_')[0]\n",
    "    df = pd.read_csv(os.path.join('custom_quorum_2', name, phase + '_info.csv'))\n",
    "    center = df['Name'].iloc[0].split('-')[0]\n",
    "    manufacturer = df['Manufacturer'].iloc[0]\n",
    "    strength = df['Field Strength'].iloc[0]\n",
    "\n",
    "    centers = update_dict(centers, str(center), filename)\n",
    "    manufacturers = update_dict(manufacturers, str(manufacturer), filename)\n",
    "    strengths = update_dict(strengths, str(strength), filename)\n",
    "    phases = update_dict(phases, str(phase), filename)\n",
    "\n",
    "with open(r'quorum_output_2\\fold_0\\temp_allClasses\\summary.json', 'r') as fd_in:\n",
    "    metric_file = json.load(fd_in)['results']['all']\n",
    "    results_dict = {}\n",
    "    for current_dict in [centers, manufacturers, strengths, phases]:\n",
    "        for key in current_dict.keys():\n",
    "            print(f'{key} = {len(current_dict[key])}')\n",
    "            current_values = current_dict[key]\n",
    "            list_of_dict = [x for x in metric_file if x['reference'].split('/')[-1] in current_values]\n",
    "            mean_dice_list = []\n",
    "            mean_hausdorff_list = []\n",
    "            for data_dict in list_of_dict:\n",
    "                mean_dice_list.append([data_dict['1']['Dice'], data_dict['2']['Dice'], data_dict['3']['Dice']])\n",
    "                mean_hausdorff_list.append([data_dict['1']['Hausdorff Distance'], data_dict['2']['Hausdorff Distance'], data_dict['3']['Hausdorff Distance']])\n",
    "            class_dice = np.stack(mean_dice_list, axis=0).mean(axis=0)\n",
    "            class_hausdorff = np.stack(mean_hausdorff_list, axis=0).mean(axis=0)\n",
    "            results_dict[key] = {'Hausdorff distance': class_hausdorff.tolist(), \n",
    "                                'Mean Hausdorff distance': float(class_hausdorff.mean()), \n",
    "                                'Dice score': class_dice.tolist(),\n",
    "                                'Mean dice score': float(class_dice.mean())}\n",
    "\n",
    "with open(output_file_name, 'w') as fd:\n",
    "    yaml.safe_dump(results_dict, fd, default_flow_style=False)\n",
    "    #for results_dict in results_dicts:\n",
    "    #    for key in results_dict.keys():\n",
    "    #        fd.write(key + ': ' + str(results_dict[key]) + '\\n')\n",
    "    #    fd.write('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ED/ES volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.234375\n",
      "187504.625\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "data = nib.load(r'quorum_output\\validation_raw\\patient003_ed.nii.gz')\n",
    "zoom = data.header.get_zooms()\n",
    "pixel_volume = np.prod(zoom)\n",
    "print(pixel_volume)\n",
    "arr = data.get_fdata()\n",
    "nb_pixels = np.count_nonzero(arr == 1)\n",
    "print(nb_pixels * pixel_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.interpolate import interpn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bwperim(bw, n=4):\n",
    "    \"\"\"\n",
    "    perim = bwperim(bw, n=4)\n",
    "    Find the perimeter of objects in binary images.\n",
    "    A pixel is part of an object perimeter if its value is one and there\n",
    "    is at least one zero-valued pixel in its neighborhood.\n",
    "    By default the neighborhood of a pixel is 4 nearest pixels, but\n",
    "    if `n` is set to 8 the 8 nearest pixels will be considered.\n",
    "    Parameters\n",
    "    ----------\n",
    "      bw : A black-and-white image\n",
    "      n : Connectivity. Must be 4 or 8 (default: 8)\n",
    "    Returns\n",
    "    -------\n",
    "      perim : A boolean image\n",
    "    \"\"\"\n",
    "\n",
    "    if n not in (4,8):\n",
    "        raise ValueError('mahotas.bwperim: n must be 4 or 8')\n",
    "    rows,cols = bw.shape\n",
    "\n",
    "    # Translate image by one pixel in all directions\n",
    "    north = np.zeros((rows,cols))\n",
    "    south = np.zeros((rows,cols))\n",
    "    west = np.zeros((rows,cols))\n",
    "    east = np.zeros((rows,cols))\n",
    "\n",
    "    north[:-1,:] = bw[1:,:]\n",
    "    south[1:,:]  = bw[:-1,:]\n",
    "    west[:,:-1]  = bw[:,1:]\n",
    "    east[:,1:]   = bw[:,:-1]\n",
    "    idx = (north == bw) & \\\n",
    "          (south == bw) & \\\n",
    "          (west  == bw) & \\\n",
    "          (east  == bw)\n",
    "    if n == 8:\n",
    "        north_east = np.zeros((rows, cols))\n",
    "        north_west = np.zeros((rows, cols))\n",
    "        south_east = np.zeros((rows, cols))\n",
    "        south_west = np.zeros((rows, cols))\n",
    "        north_east[:-1, 1:]   = bw[1:, :-1]\n",
    "        north_west[:-1, :-1] = bw[1:, 1:]\n",
    "        south_east[1:, 1:]     = bw[:-1, :-1]\n",
    "        south_west[1:, :-1]   = bw[:-1, 1:]\n",
    "        idx &= (north_east == bw) & \\\n",
    "               (south_east == bw) & \\\n",
    "               (south_west == bw) & \\\n",
    "               (north_west == bw)\n",
    "    return ~idx * bw\n",
    "\n",
    "def signed_bwdist(im):\n",
    "    '''\n",
    "    Find perim and return masked image (signed/reversed)\n",
    "    '''    \n",
    "    perimeter = bwperim(im)\n",
    "\n",
    "    distance_map = bwdist(perimeter)\n",
    "\n",
    "    im = -distance_map*np.logical_not(im) + distance_map*im\n",
    "    return im\n",
    "\n",
    "def bwdist(im):\n",
    "    '''\n",
    "    Find distance map of image\n",
    "    '''\n",
    "    dist_im = distance_transform_edt(1-im)\n",
    "    return dist_im\n",
    "\n",
    "def interp_shape(arr, new_depth):\n",
    "    '''\n",
    "    Interpolate between two contours\n",
    "\n",
    "    Input: top \n",
    "            [X,Y] - Image of top contour (mask)\n",
    "           bottom\n",
    "            [X,Y] - Image of bottom contour (mask)\n",
    "           precision\n",
    "             float  - % between the images to interpolate \n",
    "                Ex: num=0.5 - Interpolate the middle image between top and bottom image\n",
    "    Output: out\n",
    "            [X,Y] - Interpolated image at num (%) between top and bottom\n",
    "\n",
    "    '''\n",
    "    X, Y, Z = arr.shape\n",
    "\n",
    "    distance_arr = []\n",
    "    for i in range(Z):\n",
    "        distance_arr.append(signed_bwdist(arr[:, :, i]))\n",
    "    distance_arr = np.stack(distance_arr, axis=-1)\n",
    "\n",
    "    x = np.arange(0, X)\n",
    "    y = np.arange(0, Y)\n",
    "    z = np.arange(0, Z)\n",
    "    points = (x, y, z)\n",
    "\n",
    "    stop = Z-1\n",
    "\n",
    "    # create ndgrids\n",
    "    grid = np.mgrid[:X, :Y, 0:stop:(new_depth * 1j)]\n",
    "    xi = np.rollaxis(grid, 0, 4)\n",
    "    xi = xi.reshape((X * Y * new_depth, 3))\n",
    "\n",
    "    out = interpn(points, distance_arr, xi)\n",
    "    out = out.reshape((X, Y, new_depth))\n",
    "\n",
    "    # Threshold distmap to values above 0\n",
    "    out = out > 0\n",
    "\n",
    "    #fig, ax = plt.subplots(2, out.shape[-1])\n",
    "    #for t in range(out.shape[-1]):\n",
    "    #    if t < arr.shape[-1]:\n",
    "    #        ax[0, t].imshow(arr[:, :, t], cmap='gray')\n",
    "    #    ax[1, t].imshow(out[:, :, t], cmap='gray')\n",
    "    #plt.show()\n",
    "\n",
    "    #print(out.shape)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "data = nib.load(r'data_saud_2\\inference\\patient030_ed.nii.gz')\n",
    "arr = data.get_fdata()\n",
    "arr = arr == 1\n",
    "\n",
    "X, Y, Z = arr.shape\n",
    "#print(arr.shape)\n",
    "# Run interpolation\n",
    "out = interp_shape(arr, Z+1)\n",
    "#print(out.shape)\n",
    "#fig, ax = plt.subplots(1, Z+1)\n",
    "#for i in range(Z+1):\n",
    "#    ax[i].imshow(out[:, :, i], cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only patient in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "\n",
    "cut_prediction_path = r'quorum_output_2\\fold_0\\temp_allClasses'\n",
    "all_prediction_path = r'data_saud_2\\inference'\n",
    "\n",
    "data_dict_cut = {}\n",
    "data_dict_all = {}\n",
    "\n",
    "path_list = glob(os.path.join(cut_prediction_path, '*.gz'))\n",
    "cut_prediction_names = []\n",
    "for path in path_list:\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    name = filename.split('_')[0]\n",
    "    df = pd.read_csv(os.path.join('custom_quorum_2', name, phase + '_info.csv'))\n",
    "    actual_name = df['Name'].to_numpy()[0]\n",
    "    spacing = (df['Space Between Slices'] - df['Slice Thickness']).to_numpy()[0]\n",
    "    cut_prediction_names.append(actual_name)\n",
    "    if phase == 'ed':\n",
    "        update_dict(data_dict_cut, 'ed', (path, spacing))\n",
    "    elif phase == 'es':\n",
    "        update_dict(data_dict_cut, 'es', (path, spacing))\n",
    "\n",
    "csv_list = glob(os.path.join(all_prediction_path, '*.csv'))\n",
    "for csv_path in csv_list:\n",
    "    filename = csv_path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    df = pd.read_csv(csv_path)\n",
    "    actual_name = df['Name'].to_numpy()[0]\n",
    "    if actual_name in cut_prediction_names:\n",
    "        spacing = (df['Space Between Slices'] - df['Slice Thickness']).to_numpy()[0]\n",
    "        path = csv_path[:-4] + '.nii.gz'\n",
    "        if phase == 'ed':\n",
    "            update_dict(data_dict_all, 'ed', (path, spacing))\n",
    "        elif phase == 'es':\n",
    "            update_dict(data_dict_all, 'es', (path, spacing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:06<00:00,  2.20s/it]\n",
      "100%|██████████| 3/3 [00:08<00:00,  2.73s/it]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "#path_list = glob(r'quorum_output_2\\temp_allClasses\\*.gz')\n",
    "\n",
    "for data_dict, output_file_name in zip([data_dict_cut, data_dict_all], ['quorum_output_volume_cut.csv', 'quorum_output_volume_all.csv']):\n",
    "    if os.path.exists(output_file_name):\n",
    "        os.remove(output_file_name)\n",
    "    results = []\n",
    "    for i, class_name in enumerate(tqdm(['RV', 'MYO', 'LV']), 1):\n",
    "        for phase in data_dict.keys():\n",
    "            list_of_tuple = data_dict[phase]\n",
    "            for path, spacing in list_of_tuple:\n",
    "                data = nib.load(path)\n",
    "                zoom = list(data.header.get_zooms())\n",
    "                arr = data.get_fdata()\n",
    "                pixel_size = np.prod(zoom)\n",
    "\n",
    "                new_depth = round((spacing * (arr.shape[-1] - 1)) / zoom[-1]) + arr.shape[-1]\n",
    "                #print(arr.shape[-1])\n",
    "                #print(new_depth)\n",
    "                #print('******************************')\n",
    "\n",
    "                class_nb_pixels = arr == i\n",
    "\n",
    "                volume_no_interp = (pixel_size * class_nb_pixels.sum()) / 1000\n",
    "                if class_name == 'MYO':\n",
    "                    volume_no_interp = volume_no_interp * 1.055\n",
    "\n",
    "                if new_depth > arr.shape[-1]:\n",
    "                    arr_interpolated = interp_shape(class_nb_pixels, new_depth)\n",
    "                    volume_interp = (pixel_size * arr_interpolated.sum()) / 1000\n",
    "                    if class_name == 'MYO':\n",
    "                        volume_interp = volume_interp * 1.055\n",
    "                else:\n",
    "                    volume_interp = volume_no_interp\n",
    "\n",
    "                results.append({'Phase': phase, 'Class': class_name, 'Volume': volume_no_interp, 'Interpolated_volume': volume_interp})\n",
    "            \n",
    "        #if class_name != 'MYO':\n",
    "        #    results[class_name].update({\n",
    "        #        'Fraction d\\'ejection': {'no_interpolation': ((results[class_name]['ed']['volume'] - results[class_name]['es']['volume']) / results[class_name]['ed']['volume']) * 100,\n",
    "        #                                'interpolated': ((results[class_name]['ed']['interpolated_volume'] - results[class_name]['es']['interpolated_volume']) / results[class_name]['ed']['interpolated_volume']) * 100},\n",
    "        #        'Volume d\\'ejection': {'no_interpolation': (results[class_name]['ed']['volume'] - results[class_name]['es']['volume']),\n",
    "        #                                'interpolated': (results[class_name]['ed']['interpolated_volume'] - results[class_name]['es']['interpolated_volume'])}\n",
    "        #                                })          \n",
    "\n",
    "    with open(output_file_name, 'w') as fd:\n",
    "        writer = csv.DictWriter(fd, fieldnames=list(results[0].keys()))\n",
    "        writer.writeheader() \n",
    "        writer.writerows(results) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "folders = [r'Quorum_trainings\\Baseline', r'Quorum_trainings\\no_trans', r'Quorum_trainings\\no_sfb', r'Quorum_trainings\\no_ds']\n",
    "results_list = []\n",
    "for folder in folders:\n",
    "    with open(os.path.join(folder, r'fold_0\\temp_allClasses\\summary.json')) as fd_json:\n",
    "        data = json.load(fd_json)\n",
    "        results = data['results']['all']\n",
    "        for res in results:\n",
    "            rv_dice = res['1']['Dice']\n",
    "            myo_dice = res['2']['Dice']\n",
    "            lv_dice = res['3']['Dice']\n",
    "            results_list.append({'Method': folder.split('\\\\')[-1], 'RV': rv_dice, 'MYO': myo_dice, 'LV': lv_dice, 'Mean': (rv_dice + myo_dice + lv_dice) / 3})\n",
    "\n",
    "with open(os.path.join('Quorum_trainings', 'jmp.csv'), 'w') as fd_csv:\n",
    "    writer = csv.DictWriter(fd_csv, fieldnames=list(results_list[0].keys()))\n",
    "    writer.writeheader() \n",
    "    writer.writerows(results_list) \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfusionMatrix:\n",
    "\n",
    "    def __init__(self, test=None, reference=None):\n",
    "\n",
    "        self.tp = None\n",
    "        self.fp = None\n",
    "        self.tn = None\n",
    "        self.fn = None\n",
    "        self.size = None\n",
    "        self.reference_empty = None\n",
    "        self.reference_full = None\n",
    "        self.test_empty = None\n",
    "        self.test_full = None\n",
    "        self.set_reference(reference)\n",
    "        self.set_test(test)\n",
    "\n",
    "    def set_test(self, test):\n",
    "\n",
    "        self.test = test\n",
    "        self.reset()\n",
    "\n",
    "    def set_reference(self, reference):\n",
    "\n",
    "        self.reference = reference\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "\n",
    "        self.tp = None\n",
    "        self.fp = None\n",
    "        self.tn = None\n",
    "        self.fn = None\n",
    "        self.size = None\n",
    "        self.test_empty = None\n",
    "        self.test_full = None\n",
    "        self.reference_empty = None\n",
    "        self.reference_full = None\n",
    "\n",
    "    def compute(self):\n",
    "\n",
    "        if self.test is None or self.reference is None:\n",
    "            raise ValueError(\"'test' and 'reference' must both be set to compute confusion matrix.\")\n",
    "\n",
    "        assert_shape(self.test, self.reference)\n",
    "\n",
    "        self.tp = int(((self.test != 0) * (self.reference != 0)).sum())\n",
    "        self.fp = int(((self.test != 0) * (self.reference == 0)).sum())\n",
    "        self.tn = int(((self.test == 0) * (self.reference == 0)).sum())\n",
    "        self.fn = int(((self.test == 0) * (self.reference != 0)).sum())\n",
    "        self.size = int(np.prod(self.reference.shape, dtype=np.int64))\n",
    "        self.test_empty = not np.any(self.test)\n",
    "        self.test_full = np.all(self.test)\n",
    "        self.reference_empty = not np.any(self.reference)\n",
    "        self.reference_full = np.all(self.reference)\n",
    "\n",
    "    def get_matrix(self):\n",
    "\n",
    "        for entry in (self.tp, self.fp, self.tn, self.fn):\n",
    "            if entry is None:\n",
    "                self.compute()\n",
    "                break\n",
    "\n",
    "        return self.tp, self.fp, self.tn, self.fn\n",
    "\n",
    "    def get_size(self):\n",
    "\n",
    "        if self.size is None:\n",
    "            self.compute()\n",
    "        return self.size\n",
    "\n",
    "    def get_existence(self):\n",
    "\n",
    "        for case in (self.test_empty, self.test_full, self.reference_empty, self.reference_full):\n",
    "            if case is None:\n",
    "                self.compute()\n",
    "                break\n",
    "\n",
    "        return self.test_empty, self.test_full, self.reference_empty, self.reference_full\n",
    "\n",
    "\n",
    "def dice(test=None, reference=None, confusion_matrix=None, nan_for_nonexisting=True, **kwargs):\n",
    "    \"\"\"2TP / (2TP + FP + FN)\"\"\"\n",
    "\n",
    "    if confusion_matrix is None:\n",
    "        confusion_matrix = ConfusionMatrix(test, reference)\n",
    "\n",
    "    tp, fp, tn, fn = confusion_matrix.get_matrix()\n",
    "    test_empty, test_full, reference_empty, reference_full = confusion_matrix.get_existence()\n",
    "\n",
    "    if test_empty and reference_empty:\n",
    "        if nan_for_nonexisting:\n",
    "            return float(\"NaN\")\n",
    "        else:\n",
    "            return 0.\n",
    "\n",
    "    return float(2. * tp / (2 * tp + fp + fn))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dice per depth level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85727813 0.91870862 0.88975411]\n",
      "[0.85125525 0.9503675  0.92224149]\n",
      "[0.81496491 0.88242957 0.88595113]\n",
      "[0.865601   0.89990146 0.89230452]\n",
      "[0.85498399 0.84753379 0.86183659]\n",
      "[0.80896762 0.91509044 0.83652693]\n",
      "[0.94568635 0.86088831 0.9479568 ]\n",
      "[0.92407612 0.90031627 0.90839191]\n",
      "[0.94200341 0.89772142 0.9633841 ]\n",
      "[0.88622391 0.93359071 0.94075803]\n",
      "[0.93152901 0.91623481 0.95633951]\n",
      "[0.82610928 0.9333228  0.93242686]\n",
      "[0.9255292  0.89393533 0.88108325]\n",
      "[0.9458467  0.87076002 0.88045608]\n",
      "[0.91147253 0.89839016 0.95945507]\n",
      "[0.74979777 0.89845404 0.94584293]\n",
      "[0.87038465 0.83833018 0.86606815]\n",
      "[0.56653339 0.78370152 0.78536067]\n",
      "[0.83022049 0.90489216 0.93878273]\n",
      "[0.84307281 0.8781236  0.94790739]\n",
      "[0.94290595 0.91856772 0.96703108]\n",
      "[0.92860577 0.93235305 0.91357425]\n",
      "[0.88386899 0.89478284 0.95482796]\n",
      "[0.88520016 0.91129737 0.9507714 ]\n",
      "[0.84851985 0.92478445 0.88103115]\n",
      "[0.71604308 0.90891398 0.84393   ]\n",
      "[0.76101985 0.86485348 0.86941596]\n",
      "[0.45169637 0.6704366  0.65358929]\n",
      "[0.94472996 0.88497189 0.94925755]\n",
      "[0.62411604 0.84808277 0.89347389]\n",
      "[0.89315145 0.90999032 0.90256508]\n",
      "[0.94903069 0.91221581 0.93988318]\n",
      "[0.93308716 0.93017875 0.9699013 ]\n",
      "[0.89410848 0.93763697 0.92493118]\n",
      "[0.86164112 0.90431886 0.9625434 ]\n",
      "[0.71919105 0.92792669 0.92681158]\n",
      "[0.82588679 0.921958   0.96065385]\n",
      "[0.69483021 0.91199901 0.93044079]\n",
      "[0.84517152 0.79711726 0.914523  ]\n",
      "[0.83214915 0.84901049 0.94244053]\n",
      "[0.80392956 0.93121396 0.96027419]\n",
      "[0.69754341 0.91996281 0.95280821]\n",
      "[0.88653996 0.8782918  0.95787335]\n",
      "[0.81376271 0.91351446 0.95785695]\n",
      "[0.92566507 0.89217999 0.97111853]\n",
      "[0.79272607 0.91591664 0.95437219]\n",
      "[0.92176616 0.86023314 0.89605092]\n",
      "[0.73278843 0.90077135 0.95767437]\n",
      "[0.91553328 0.90811986 0.94235504]\n",
      "[0.87117304 0.88501796 0.93600059]\n",
      "[0.89556321 0.89882837 0.95980807]\n",
      "[0.75563434 0.89775115 0.95769537]\n",
      "[0.81903282 0.88346735 0.88999915]\n",
      "[0.86084161 0.91693887 0.91638356]\n",
      "[0.93730609 0.9033173  0.9730138 ]\n",
      "[0.93406996 0.88501444 0.92645748]\n",
      "[0.94059712 0.88133944 0.96047556]\n",
      "[0.89431896 0.89530755 0.93153321]\n",
      "[0.92764897 0.89531392 0.89518584]\n",
      "[0.79138982 0.90809595 0.8343921 ]\n",
      "[0.923283   0.91278844 0.97117047]\n",
      "[0.87283981 0.87961365 0.94152538]\n",
      "[0.90251191 0.92391501 0.95058586]\n",
      "[0.82799012 0.90838294 0.88055742]\n",
      "[0.83168935 0.89155762 0.85923913]\n",
      "[0.7766177  0.86592385 0.82093531]\n",
      "[0.79170973 0.88421035 0.89673911]\n",
      "[0.78913838 0.88596517 0.90754461]\n",
      "[0.69876153 0.75355363 0.90637923]\n",
      "[0.6821699  0.73689096 0.8067542 ]\n",
      "[0.82736787 0.8984606  0.92282925]\n",
      "[0.78276783 0.91621455 0.95415727]\n",
      "[0.54453752 0.5194856  0.79003696]\n",
      "[0.43141938 0.66385547 0.72357546]\n",
      "[0.9399533  0.87950202 0.95528473]\n",
      "[0.79352809 0.8457169  0.93714579]\n",
      "[0.80071947 0.89675939 0.9590026 ]\n",
      "[0.86635894 0.9306531  0.90607527]\n",
      "[0.84654779 0.90209529 0.9522925 ]\n",
      "[0.87677283 0.93454146 0.92605737]\n",
      "[0.83138756 0.88230964 0.91367051]\n",
      "0.8757892400017635\n"
     ]
    }
   ],
   "source": [
    "from evaluation.metrics import dice\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from glob import glob\n",
    "import math\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "path_list = glob(r'quorum_output_2\\fold_0\\temp_allClasses\\*.gz')\n",
    "path_list_names = [x.split('\\\\')[-1][:13] for x in path_list]\n",
    "path_list_gt = glob(r'custom_quorum_2\\**\\*_gt.nii.gz', recursive=True)\n",
    "path_list_gt = [x for x in path_list_gt if x.split('\\\\')[-1][:13] in path_list_names]\n",
    "assert len(path_list_gt) == len(path_list)\n",
    "\n",
    "path_list = sorted(path_list, key=lambda x:x.split('\\\\')[-1])\n",
    "path_list_gt = sorted(path_list_gt, key=lambda x:x.split('\\\\')[-1])\n",
    "\n",
    "out_dict = {}\n",
    "scores = []\n",
    "for path, path_gt in zip(path_list, path_list_gt):\n",
    "    data = nib.load(path)\n",
    "    arr = data.get_fdata()\n",
    "\n",
    "    data_gt = nib.load(path_gt)\n",
    "    arr_gt = data_gt.get_fdata()\n",
    "\n",
    "    assert arr.shape == arr_gt.shape\n",
    "    patient_scores = []\n",
    "    for i in range(arr.shape[-1]):\n",
    "        #fig, ax = plt.subplots(1, 2)\n",
    "        #ax[0].imshow(arr[:, :, i], cmap='gray')\n",
    "        #ax[1].imshow(arr_gt[:, :, i], cmap='gray')\n",
    "        #plt.show()\n",
    "        #plt.waitforbuttonpress()\n",
    "        #plt.close(fig)\n",
    "\n",
    "        current_pred = arr[:, :, i]\n",
    "        current_gt = arr_gt[:, :, i]\n",
    "\n",
    "        #current_pred = arr\n",
    "        #current_gt = arr_gt\n",
    "\n",
    "        class_score = []\n",
    "        for j in range(1, 4):\n",
    "            current_class_pred = current_pred == j\n",
    "            current_gt_pred = current_gt == j\n",
    "            score = dice(current_class_pred, current_gt_pred)\n",
    "            class_score.append(score)\n",
    "        out_dict = update_dict(out_dict, key=i/arr.shape[-1], value=np.nanmean(np.array(class_score)))\n",
    "        patient_scores.append(np.array(class_score))\n",
    "    patient_class_score = np.stack(patient_scores, axis=0)\n",
    "    patient_class_score = np.nanmean(patient_class_score, axis=0)\n",
    "    scores.append(patient_class_score)\n",
    "scores = np.stack(scores, 0)\n",
    "scores = np.nanmean(scores, axis=0)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for key in out_dict.keys():\n",
    "    x.append(key)\n",
    "    y.append(np.array(out_dict[key]).mean())\n",
    "\n",
    "print(np.array(scores).mean())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(np.array(x), np.array(y))\n",
    "ax.set(xlabel='Depth as percent of volume', ylabel='Dice score')\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5 (tags/v3.9.5:0a7dcbd, May  3 2021, 17:27:52) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de6e7f1d27ee98e0dd03d720850162ba8f013030d5557c31bd8d79f8fd588abc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
