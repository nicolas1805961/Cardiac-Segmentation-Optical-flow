{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get results by criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "flipped_list = ['250005-003','250005-004','250005-007','276004-001','348003-002','703001-018','703003-010']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "results_list = []\n",
    "with open(r'Quorum_output_2\\all_data\\only_sfb\\temp_allClasses\\summary.json', 'r') as fd_in:\n",
    "    metric_file = json.load(fd_in)['results']['all']\n",
    "    for data_dict in metric_file:\n",
    "        name = data_dict['center']\n",
    "        center = name.split('-')[0]\n",
    "        manufacturer = data_dict['manufacturer']\n",
    "        phase = data_dict['reference'].split('\\\\')[-1][11:13]\n",
    "        #if name in flipped_list:\n",
    "        #    if phase == 'es':\n",
    "        #        phase = 'ed'\n",
    "        #    elif phase == 'ed':\n",
    "        #        phase = 'es'\n",
    "        #    else:\n",
    "        #        print('BUG !!!!!!')\n",
    "        field_strength = str(data_dict['strength'])\n",
    "\n",
    "        rv_dice = data_dict['1']['Dice']\n",
    "        myo_dice = data_dict['2']['Dice']\n",
    "        lv_dice = data_dict['3']['Dice']\n",
    "        dice = (rv_dice + myo_dice + lv_dice) / 3\n",
    "\n",
    "        rv_hd = data_dict['1']['Hausdorff Distance']\n",
    "        myo_hd = data_dict['2']['Hausdorff Distance']\n",
    "        lv_hd = data_dict['3']['Hausdorff Distance']\n",
    "        hd = (rv_hd + myo_hd + lv_hd) / 3\n",
    "\n",
    "        results_list.append({'Name': name, \n",
    "                            'Center': center, \n",
    "                            'Manufacturer': manufacturer, \n",
    "                            'Phase': phase, \n",
    "                            'Field Strength': field_strength, \n",
    "                            'RV dice': rv_dice,\n",
    "                            'MYO dice': myo_dice,\n",
    "                            'LV dice': lv_dice,\n",
    "                            'Mean dice': dice, \n",
    "                            'RV HD': rv_hd,\n",
    "                            'MYO HD': myo_hd,\n",
    "                            'LV HD': lv_hd,\n",
    "                            'Mean HD': hd,\n",
    "                            })\n",
    "\n",
    "with open(os.path.join('Quorum_output_2', 'Criteria_jmp.csv'), 'w') as fd_csv:\n",
    "    writer = csv.DictWriter(fd_csv, fieldnames=list(results_list[0].keys()))\n",
    "    writer.writeheader() \n",
    "    writer.writerows(results_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "siemens = 248\n",
      "philips = 14\n",
      "ge = 48\n",
      "1.5 = 280\n",
      "3.0 = 30\n",
      "ed = 155\n",
      "es = 155\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "with open(r'splits_final.pkl', 'rb') as fd:\n",
    "    data = pickle.load(fd)\n",
    "    train_names = data[0]['train']\n",
    "    train_names = [x[:-3] for x in train_names]\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "centers = {}\n",
    "manufacturers = {}\n",
    "strengths = {}\n",
    "depths = {}\n",
    "phases = {}\n",
    "path_list = glob(r'custom_quorum\\**\\*.csv')\n",
    "for path in path_list:\n",
    "    df = pd.read_csv(path)\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    patient_name = path.split('\\\\')[-2]\n",
    "    phase = filename[:2]\n",
    "    manufacturer = df['Manufacturer'].iloc[0]\n",
    "    strength = df['Field Strength'].iloc[0]\n",
    "\n",
    "    if patient_name in train_names:\n",
    "        manufacturers = update_dict(manufacturers, str(manufacturer), filename)\n",
    "        strengths = update_dict(strengths, str(strength), filename)\n",
    "        phases = update_dict(phases, str(phase), filename)\n",
    "\n",
    "for current_dict in [manufacturers, strengths, phases]:\n",
    "    for k in current_dict.keys():\n",
    "        print(f'{k} = {len(current_dict[k])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250001 = 10\n",
      "250005 = 2\n",
      "276004 = 2\n",
      "276005 = 2\n",
      "276008 = 2\n",
      "348001 = 6\n",
      "348002 = 6\n",
      "348003 = 2\n",
      "348004 = 8\n",
      "348007 = 6\n",
      "616003 = 4\n",
      "616005 = 2\n",
      "616010 = 2\n",
      "703001 = 10\n",
      "703003 = 2\n",
      "703004 = 8\n",
      "724002 = 2\n",
      "724006 = 4\n",
      "siemens = 62\n",
      "philips = 4\n",
      "ge = 14\n",
      "1.5 = 66\n",
      "3.0 = 14\n",
      "ed = 40\n",
      "es = 40\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "output_file_name = 'quorum_output_field.yaml'\n",
    "if os.path.exists(output_file_name):\n",
    "    os.remove(output_file_name)\n",
    "\n",
    "centers = {}\n",
    "manufacturers = {}\n",
    "strengths = {}\n",
    "depths = {}\n",
    "phases = {}\n",
    "\n",
    "path_list = glob(r'Quorum_output_2\\only_sfb\\fold_0\\temp_allClasses\\*.gz')\n",
    "for path in path_list:\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    name = filename.split('_')[0]\n",
    "    df = pd.read_csv(os.path.join('custom_quorum_2', name, phase + '_info.csv'))\n",
    "    center = df['Name'].iloc[0].split('-')[0]\n",
    "    manufacturer = df['Manufacturer'].iloc[0]\n",
    "    strength = df['Field Strength'].iloc[0]\n",
    "\n",
    "    centers = update_dict(centers, str(center), filename)\n",
    "    manufacturers = update_dict(manufacturers, str(manufacturer), filename)\n",
    "    strengths = update_dict(strengths, str(strength), filename)\n",
    "    phases = update_dict(phases, str(phase), filename)\n",
    "\n",
    "with open(r'Quorum_output_2\\only_sfb\\fold_0\\temp_allClasses\\summary.json', 'r') as fd_in:\n",
    "    metric_file = json.load(fd_in)['results']['all']\n",
    "    results_dict = {}\n",
    "    for current_dict, criteria_name in zip([centers, manufacturers, strengths, phases], ['Center', 'Manufacturer', 'Field Strength', 'Phase']):\n",
    "        for key in current_dict.keys():\n",
    "            print(f'{key} = {len(current_dict[key])}')\n",
    "            current_values = current_dict[key]\n",
    "            list_of_dict = [x for x in metric_file if x['reference'].split('/')[-1] in current_values]\n",
    "            mean_dice_list = []\n",
    "            mean_hausdorff_list = []\n",
    "            for data_dict in list_of_dict:\n",
    "                rv_dice = data_dict['1']['Dice']\n",
    "                myo_dice = data_dict['2']['Dice']\n",
    "                lv_dice = data_dict['3']['Dice']\n",
    "                results_list.append({criteria_name: key, 'RV': rv_dice, 'MYO': myo_dice, 'LV': lv_dice, 'Mean': (rv_dice + myo_dice + lv_dice) / 3})\n",
    "                mean_dice_list.append([data_dict['1']['Dice'], data_dict['2']['Dice'], data_dict['3']['Dice']])\n",
    "                mean_hausdorff_list.append([data_dict['1']['Hausdorff Distance'], data_dict['2']['Hausdorff Distance'], data_dict['3']['Hausdorff Distance']])\n",
    "            class_dice = np.stack(mean_dice_list, axis=0).mean(axis=0)\n",
    "            class_hausdorff = np.stack(mean_hausdorff_list, axis=0).mean(axis=0)\n",
    "            results_dict[key] = {'Hausdorff distance': class_hausdorff.tolist(), \n",
    "                                'Mean Hausdorff distance': float(class_hausdorff.mean()), \n",
    "                                'Dice score': class_dice.tolist(),\n",
    "                                'Mean dice score': float(class_dice.mean())}\n",
    "\n",
    "with open(output_file_name, 'w') as fd:\n",
    "    yaml.safe_dump(results_dict, fd, default_flow_style=False)\n",
    "    #for results_dict in results_dicts:\n",
    "    #    for key in results_dict.keys():\n",
    "    #        fd.write(key + ': ' + str(results_dict[key]) + '\\n')\n",
    "    #    fd.write('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ED/ES volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.234375\n",
      "187504.625\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "data = nib.load(r'quorum_output\\validation_raw\\patient003_ed.nii.gz')\n",
    "zoom = data.header.get_zooms()\n",
    "pixel_volume = np.prod(zoom)\n",
    "print(pixel_volume)\n",
    "arr = data.get_fdata()\n",
    "nb_pixels = np.count_nonzero(arr == 1)\n",
    "print(nb_pixels * pixel_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.interpolate import interpn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bwperim(bw, n=4):\n",
    "    \"\"\"\n",
    "    perim = bwperim(bw, n=4)\n",
    "    Find the perimeter of objects in binary images.\n",
    "    A pixel is part of an object perimeter if its value is one and there\n",
    "    is at least one zero-valued pixel in its neighborhood.\n",
    "    By default the neighborhood of a pixel is 4 nearest pixels, but\n",
    "    if `n` is set to 8 the 8 nearest pixels will be considered.\n",
    "    Parameters\n",
    "    ----------\n",
    "      bw : A black-and-white image\n",
    "      n : Connectivity. Must be 4 or 8 (default: 8)\n",
    "    Returns\n",
    "    -------\n",
    "      perim : A boolean image\n",
    "    \"\"\"\n",
    "\n",
    "    if n not in (4,8):\n",
    "        raise ValueError('mahotas.bwperim: n must be 4 or 8')\n",
    "    rows,cols = bw.shape\n",
    "\n",
    "    # Translate image by one pixel in all directions\n",
    "    north = np.zeros((rows,cols))\n",
    "    south = np.zeros((rows,cols))\n",
    "    west = np.zeros((rows,cols))\n",
    "    east = np.zeros((rows,cols))\n",
    "\n",
    "    north[:-1,:] = bw[1:,:]\n",
    "    south[1:,:]  = bw[:-1,:]\n",
    "    west[:,:-1]  = bw[:,1:]\n",
    "    east[:,1:]   = bw[:,:-1]\n",
    "    idx = (north == bw) & \\\n",
    "          (south == bw) & \\\n",
    "          (west  == bw) & \\\n",
    "          (east  == bw)\n",
    "    if n == 8:\n",
    "        north_east = np.zeros((rows, cols))\n",
    "        north_west = np.zeros((rows, cols))\n",
    "        south_east = np.zeros((rows, cols))\n",
    "        south_west = np.zeros((rows, cols))\n",
    "        north_east[:-1, 1:]   = bw[1:, :-1]\n",
    "        north_west[:-1, :-1] = bw[1:, 1:]\n",
    "        south_east[1:, 1:]     = bw[:-1, :-1]\n",
    "        south_west[1:, :-1]   = bw[:-1, 1:]\n",
    "        idx &= (north_east == bw) & \\\n",
    "               (south_east == bw) & \\\n",
    "               (south_west == bw) & \\\n",
    "               (north_west == bw)\n",
    "    return ~idx * bw\n",
    "\n",
    "def signed_bwdist(im):\n",
    "    '''\n",
    "    Find perim and return masked image (signed/reversed)\n",
    "    '''    \n",
    "    perimeter = bwperim(im)\n",
    "\n",
    "    distance_map = bwdist(perimeter)\n",
    "\n",
    "    im = -distance_map*np.logical_not(im) + distance_map*im\n",
    "    return im\n",
    "\n",
    "def bwdist(im):\n",
    "    '''\n",
    "    Find distance map of image\n",
    "    '''\n",
    "    dist_im = distance_transform_edt(1-im)\n",
    "    return dist_im\n",
    "\n",
    "def interp_shape(arr, new_depth):\n",
    "    '''\n",
    "    Interpolate between two contours\n",
    "\n",
    "    Input: top \n",
    "            [X,Y] - Image of top contour (mask)\n",
    "           bottom\n",
    "            [X,Y] - Image of bottom contour (mask)\n",
    "           precision\n",
    "             float  - % between the images to interpolate \n",
    "                Ex: num=0.5 - Interpolate the middle image between top and bottom image\n",
    "    Output: out\n",
    "            [X,Y] - Interpolated image at num (%) between top and bottom\n",
    "\n",
    "    '''\n",
    "    X, Y, Z = arr.shape\n",
    "\n",
    "    distance_arr = []\n",
    "    for i in range(Z):\n",
    "        distance_arr.append(signed_bwdist(arr[:, :, i]))\n",
    "    distance_arr = np.stack(distance_arr, axis=-1)\n",
    "\n",
    "    x = np.arange(0, X)\n",
    "    y = np.arange(0, Y)\n",
    "    z = np.arange(0, Z)\n",
    "    points = (x, y, z)\n",
    "\n",
    "    stop = Z-1\n",
    "\n",
    "    # create ndgrids\n",
    "    grid = np.mgrid[:X, :Y, 0:stop:(new_depth * 1j)]\n",
    "    xi = np.rollaxis(grid, 0, 4)\n",
    "    xi = xi.reshape((X * Y * new_depth, 3))\n",
    "\n",
    "    out = interpn(points, distance_arr, xi)\n",
    "    out = out.reshape((X, Y, new_depth))\n",
    "\n",
    "    # Threshold distmap to values above 0\n",
    "    out = out > 0\n",
    "\n",
    "    #fig, ax = plt.subplots(2, out.shape[-1])\n",
    "    #for t in range(out.shape[-1]):\n",
    "    #    if t < arr.shape[-1]:\n",
    "    #        ax[0, t].imshow(arr[:, :, t], cmap='gray')\n",
    "    #    ax[1, t].imshow(out[:, :, t], cmap='gray')\n",
    "    #plt.show()\n",
    "\n",
    "    #print(out.shape)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "data = nib.load(r'data_saud_2\\inference\\patient030_ed.nii.gz')\n",
    "arr = data.get_fdata()\n",
    "arr = arr == 1\n",
    "\n",
    "X, Y, Z = arr.shape\n",
    "#print(arr.shape)\n",
    "# Run interpolation\n",
    "out = interp_shape(arr, Z+1)\n",
    "#print(out.shape)\n",
    "#fig, ax = plt.subplots(1, Z+1)\n",
    "#for i in range(Z+1):\n",
    "#    ax[i].imshow(out[:, :, i], cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get only patient in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "\n",
    "cut_prediction_path = r'Quorum_output_2\\only_sfb\\fold_0\\temp_allClasses'\n",
    "all_prediction_path = r'data_saud_2\\inference'\n",
    "\n",
    "data_dict_cut = {}\n",
    "data_dict_all = {}\n",
    "\n",
    "path_list = glob(os.path.join(cut_prediction_path, '*.gz'))\n",
    "cut_prediction_names = []\n",
    "for path in path_list:\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    name = filename.split('_')[0]\n",
    "    df = pd.read_csv(os.path.join('custom_quorum_2', name, phase + '_info.csv'))\n",
    "    actual_name = df['Name'].to_numpy()[0]\n",
    "    spacing = (df['Space Between Slices'] - df['Slice Thickness']).to_numpy()[0]\n",
    "    cut_prediction_names.append(actual_name)\n",
    "    if phase == 'ed':\n",
    "        update_dict(data_dict_cut, 'ed', (path, spacing, actual_name))\n",
    "    elif phase == 'es':\n",
    "        update_dict(data_dict_cut, 'es', (path, spacing, actual_name))\n",
    "\n",
    "csv_list = glob(os.path.join(all_prediction_path, '*.csv'))\n",
    "for csv_path in csv_list:\n",
    "    filename = csv_path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    df = pd.read_csv(csv_path)\n",
    "    actual_name = df['Name'].to_numpy()[0]\n",
    "    if actual_name in cut_prediction_names:\n",
    "        spacing = (df['Space Between Slices'] - df['Slice Thickness']).to_numpy()[0]\n",
    "        path = csv_path[:-4] + '.nii.gz'\n",
    "        if phase == 'ed':\n",
    "            update_dict(data_dict_all, 'ed', (path, spacing, actual_name))\n",
    "        elif phase == 'es':\n",
    "            update_dict(data_dict_all, 'es', (path, spacing, actual_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [00:08<00:00,  4.80it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "\n",
    "def get_volume(arr_ed, arr_es, zoom, spacing_ed, spacing_es):\n",
    "    pixel_size = np.prod(zoom)\n",
    "    new_depth_ed = round((spacing_ed * (arr_ed.shape[-1] - 1)) / zoom[-1]) + arr_ed.shape[-1]\n",
    "    new_depth_es = round((spacing_es * (arr_es.shape[-1] - 1)) / zoom[-1]) + arr_es.shape[-1]\n",
    "\n",
    "    class_nb_pixels_ed = arr_ed == i\n",
    "    class_nb_pixels_es = arr_es == i\n",
    "\n",
    "    volume_no_interp_ed = (pixel_size * class_nb_pixels_ed.sum()) / 1000\n",
    "    volume_no_interp_es = (pixel_size * class_nb_pixels_es.sum()) / 1000\n",
    "    if class_name == 'MYO':\n",
    "        volume_no_interp_ed = volume_no_interp_ed * 1.055\n",
    "        volume_no_interp_es = volume_no_interp_es * 1.055\n",
    "\n",
    "    if new_depth_ed > arr_ed.shape[-1]:\n",
    "        arr_interpolated_ed = interp_shape(class_nb_pixels_ed, new_depth_ed)\n",
    "        volume_interp_ed = (pixel_size * arr_interpolated_ed.sum()) / 1000\n",
    "        if class_name == 'MYO':\n",
    "            volume_interp_ed = volume_interp_ed * 1.055\n",
    "    else:\n",
    "        volume_interp_ed = volume_no_interp_ed\n",
    "\n",
    "    if new_depth_es > arr_es.shape[-1]:\n",
    "        arr_interpolated_es = interp_shape(class_nb_pixels_es, new_depth_es)\n",
    "        volume_interp_es = (pixel_size * arr_interpolated_es.sum()) / 1000\n",
    "        if class_name == 'MYO':\n",
    "            volume_interp_es = volume_interp_es * 1.055\n",
    "    else:\n",
    "        volume_interp_es = volume_no_interp_es\n",
    "    \n",
    "    return volume_no_interp_ed, volume_no_interp_es, volume_interp_ed, volume_interp_es\n",
    "\n",
    "df = pd.read_excel('Quorum_Qmass_12_07_2021.xlsx')\n",
    "#df_keep = pd.read_csv(r'data_saud_2\\keep.csv', converters={\"Slices\": lambda x: list(map(int, x.strip(\"[]\").split(\", \")))})\n",
    "\n",
    "name_list = []\n",
    "results_list = []\n",
    "with open(r'Quorum_output_2\\all_data\\only_sfb\\temp_allClasses\\summary.json', 'r') as fd_in:\n",
    "    metric_file = json.load(fd_in)['results']['all']\n",
    "    for idx in tqdm(range(0, len(metric_file), 2)):\n",
    "        spacing_ed = float(metric_file[idx]['spacing between slices']) - float(metric_file[idx]['slice thickness'])\n",
    "        spacing_es = float(metric_file[idx+1]['spacing between slices']) - float(metric_file[idx+1]['slice thickness'])\n",
    "        name1 = metric_file[idx]['center']\n",
    "        name2 = metric_file[idx+1]['center']\n",
    "\n",
    "        assert name1 == name2\n",
    "        name_list.append(name1)\n",
    "\n",
    "        path1 = metric_file[idx]['test']\n",
    "        path2 = metric_file[idx+1]['test']\n",
    "        filename1 = path1.split('\\\\')[-1]\n",
    "        filename2 = path2.split('\\\\')[-1]\n",
    "        #if name1 in flipped_list:\n",
    "        #    data_ed = nib.load(os.path.join(r'Quorum_output_2\\only_sfb\\temp_allClasses', filename2))\n",
    "        #    data_es = nib.load(os.path.join(r'Quorum_output_2\\only_sfb\\temp_allClasses', filename1))\n",
    "        #else:\n",
    "        data_ed = nib.load(os.path.join(r'Quorum_output_2\\all_data\\only_sfb\\temp_allClasses', filename1))\n",
    "        data_es = nib.load(os.path.join(r'Quorum_output_2\\all_data\\only_sfb\\temp_allClasses', filename2))\n",
    "        zoom = list(data_ed.header.get_zooms())\n",
    "        arr_ed = data_ed.get_fdata()\n",
    "        arr_es = data_es.get_fdata()\n",
    "\n",
    "        assert spacing_ed == spacing_es\n",
    "\n",
    "        right_slices = np.arange(min(arr_es.shape[-1], arr_ed.shape[-1]))\n",
    "\n",
    "        arr_ed_keep = arr_ed[:, :, right_slices]\n",
    "        arr_es_keep = arr_es[:, :, right_slices]\n",
    "\n",
    "        class_volume = {'Patient ID': name1}\n",
    "        for i, class_name in enumerate(['RV', 'MYO', 'LV'], 1):\n",
    "            volume_no_interp_ed, volume_no_interp_es, volume_interp_ed, volume_interp_es = get_volume(arr_ed_keep, arr_es_keep, zoom, spacing_ed, spacing_es)\n",
    "\n",
    "            class_volume[class_name + 'EF_pred'] = ((volume_no_interp_ed - volume_no_interp_es) / volume_no_interp_ed) * 100\n",
    "            class_volume[class_name + 'EV_pred'] = (volume_no_interp_ed - volume_no_interp_es)\n",
    "            class_volume[class_name + 'EF_interp_pred'] = ((volume_interp_ed - volume_interp_es) / volume_interp_ed) * 100\n",
    "            class_volume[class_name + 'EV_interp_pred'] = (volume_interp_ed - volume_interp_es)\n",
    "\n",
    "            volume_no_interp_ed, volume_no_interp_es, volume_interp_ed, volume_interp_es = get_volume(arr_ed, arr_es, zoom, spacing_ed, spacing_es)\n",
    "\n",
    "            class_volume[class_name + 'EDV_pred'] = volume_no_interp_ed\n",
    "            class_volume[class_name + 'ESV_pred'] = volume_no_interp_es\n",
    "            class_volume[class_name + 'EDV_interp_pred'] = volume_interp_ed\n",
    "            class_volume[class_name + 'ESV_interp_pred'] = volume_interp_es\n",
    "        results_list.append(class_volume)\n",
    "\n",
    "df_pred = pd.DataFrame.from_records(results_list)\n",
    "\n",
    "new_df = df.loc[(df['Patient ID'].isin(name_list)) & (df['Study description'] == 'Baseline_MRI')]\n",
    "\n",
    "out = pd.merge(new_df, df_pred, on='Patient ID')\n",
    "\n",
    "out.to_csv(r'Quorum_output_2\\volume.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(256, 256, 12)\n",
      "(256, 256, 6)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14652/1828118114.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitforbuttonpress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mwaitforbuttonpress\u001b[1;34m(timeout)\u001b[0m\n\u001b[0;32m   2306\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitforbuttonpress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2307\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwaitforbuttonpress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2308\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitforbuttonpress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mwaitforbuttonpress\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   3123\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3125\u001b[1;33m         _blocking_input.blocking_input_loop(\n\u001b[0m\u001b[0;32m   3126\u001b[0m             self, [\"button_press_event\", \"key_press_event\"], timeout, handler)\n\u001b[0;32m   3127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\_blocking_input.py\u001b[0m in \u001b[0;36mblocking_input_loop\u001b[1;34m(figure, event_names, timeout, handler)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mcids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpl_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevent_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Start event loop.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Run even on exception like ctrl-c.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Disconnect the callbacks.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\backends\\backend_qt.py\u001b[0m in \u001b[0;36mstart_event_loop\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_maybe_allow_interrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_loop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mqt_compat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_loop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstop_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\backends\\qt_compat.py\u001b[0m in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_sigint_handler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhandler_args\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                 \u001b[0mold_sigint_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mhandler_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = nib.load(r'Quorum_output_2\\only_sfb\\fold_0\\temp_allClasses\\patient108_ed.nii.gz')\n",
    "arr = data.get_fdata()\n",
    "\n",
    "data2 = nib.load(r'Quorum_output_2\\only_sfb\\fold_0\\temp_allClasses\\patient108_es.nii.gz')\n",
    "arr2 = data2.get_fdata()\n",
    "\n",
    "print(arr2.shape)\n",
    "print(arr.shape)\n",
    "\n",
    "for i in range(arr.shape[-1]):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(arr[:, :, i], cmap='gray')\n",
    "    ax[1].imshow(arr[:, :, i], cmap='gray')\n",
    "    plt.waitforbuttonpress()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get volume and diseases for jmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:07<00:00,  2.37s/it]\n",
      "100%|██████████| 3/3 [00:11<00:00,  3.72s/it]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "\n",
    "df_disease = pd.read_excel(r'disease_saud\\radiomics_all.xlsx')\n",
    "payload_disease = df_disease.loc[df_disease['Descriptor'] == 'Infarction_Ratio']\n",
    "\n",
    "#path_list = glob(r'quorum_output_2\\temp_allClasses\\*.gz')\n",
    "\n",
    "for data_dict, output_file_name in zip([data_dict_cut, data_dict_all], ['disease_volume_cut.csv', 'disease_volume_all.csv']):\n",
    "    if os.path.exists(output_file_name):\n",
    "        os.remove(output_file_name)\n",
    "    results = []\n",
    "    for i, class_name in enumerate(tqdm(['RV', 'MYO', 'LV']), 1):\n",
    "        for phase in data_dict.keys():\n",
    "            list_of_tuple = data_dict[phase]\n",
    "            for path, spacing, name in list_of_tuple:\n",
    "                data = nib.load(path)\n",
    "                zoom = list(data.header.get_zooms())\n",
    "                arr = data.get_fdata()\n",
    "                pixel_size = np.prod(zoom)\n",
    "\n",
    "                new_depth = round((spacing * (arr.shape[-1] - 1)) / zoom[-1]) + arr.shape[-1]\n",
    "                #print(arr.shape[-1])\n",
    "                #print(new_depth)\n",
    "                #print('******************************')\n",
    "\n",
    "                class_nb_pixels = arr == i\n",
    "\n",
    "                volume_no_interp = (pixel_size * class_nb_pixels.sum()) / 1000\n",
    "                if class_name == 'MYO':\n",
    "                    volume_no_interp = volume_no_interp * 1.055\n",
    "\n",
    "                if new_depth > arr.shape[-1]:\n",
    "                    arr_interpolated = interp_shape(class_nb_pixels, new_depth)\n",
    "                    volume_interp = (pixel_size * arr_interpolated.sum()) / 1000\n",
    "                    if class_name == 'MYO':\n",
    "                        volume_interp = volume_interp * 1.055\n",
    "                else:\n",
    "                    volume_interp = volume_no_interp\n",
    "\n",
    "                if name in payload_disease:\n",
    "                    infraction_percent = payload_disease[name][0]\n",
    "                else:\n",
    "                    infraction_percent = ''\n",
    "\n",
    "                results.append({'Phase': phase, 'Class': class_name, 'Volume': volume_no_interp, 'Interpolated_volume': volume_interp, 'Infraction_percent': infraction_percent})\n",
    "            \n",
    "        #if class_name != 'MYO':\n",
    "        #    results[class_name].update({\n",
    "        #        'Fraction d\\'ejection': {'no_interpolation': ((results[class_name]['ed']['volume'] - results[class_name]['es']['volume']) / results[class_name]['ed']['volume']) * 100,\n",
    "        #                                'interpolated': ((results[class_name]['ed']['interpolated_volume'] - results[class_name]['es']['interpolated_volume']) / results[class_name]['ed']['interpolated_volume']) * 100},\n",
    "        #        'Volume d\\'ejection': {'no_interpolation': (results[class_name]['ed']['volume'] - results[class_name]['es']['volume']),\n",
    "        #                                'interpolated': (results[class_name]['ed']['interpolated_volume'] - results[class_name]['es']['interpolated_volume'])}\n",
    "        #                                })          \n",
    "\n",
    "    with open(os.path.join(r'Quorum_output_2', output_file_name), 'w') as fd:\n",
    "        writer = csv.DictWriter(fd, fieldnames=list(results[0].keys()))\n",
    "        writer.writeheader() \n",
    "        writer.writerows(results) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get disease and dice for jmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_excel(r'disease_saud\\radiomics_all.xlsx')\n",
    "payload = df.loc[df['Descriptor'] == 'Infarction_Ratio']\n",
    "\n",
    "folders = [r'Quorum_output_2\\only_sfb\\fold_0']\n",
    "for folder in folders:\n",
    "    results_list = []\n",
    "    with open(os.path.join(folder, r'temp_allClasses\\summary.json')) as fd_json:\n",
    "        data = json.load(fd_json)\n",
    "        results = data['results']['all']\n",
    "        for res in results:\n",
    "            rv_dice = res['1']['Dice']\n",
    "            myo_dice = res['2']['Dice']\n",
    "            lv_dice = res['3']['Dice']\n",
    "            patient_name = res['center']\n",
    "            if patient_name in payload:\n",
    "                infraction_percent = payload[patient_name][0]\n",
    "            else:\n",
    "                infraction_percent = ''\n",
    "            results_list.append({'Patient': patient_name, 'Infraction_percent': infraction_percent, 'RV': rv_dice, 'MYO': myo_dice, 'LV': lv_dice, 'Mean': (rv_dice + myo_dice + lv_dice) / 3})\n",
    "\n",
    "    with open(os.path.join(folder, 'disease_jmp.csv'), 'w') as fd_csv:\n",
    "        writer = csv.DictWriter(fd_csv, fieldnames=list(results_list[0].keys()))\n",
    "        writer.writeheader() \n",
    "        writer.writerows(results_list) \n",
    "        "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get jmp data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "folders = [r'Quorum_output_2\\all_data\\only_sfb', r'Quorum_output_2\\all_data\\no_transformer', r'Quorum_output_2\\all_data\\no_sfb', r'Quorum_output_2\\all_data\\no_ds']\n",
    "results_list = []\n",
    "for folder in folders:\n",
    "    with open(os.path.join(folder, r'validation_raw\\summary.json')) as fd_json:\n",
    "        data = json.load(fd_json)\n",
    "        results = data['results']['all']\n",
    "        for res in results:\n",
    "            name = res['test'].split('\\\\')[-1].split('.')[0]\n",
    "            rv_hd = res['1']['Hausdorff Distance']\n",
    "            myo_hd = res['2']['Hausdorff Distance']\n",
    "            lv_hd = res['3']['Hausdorff Distance']\n",
    "            rv_dice = res['1']['Dice']\n",
    "            myo_dice = res['2']['Dice']\n",
    "            lv_dice = res['3']['Dice']\n",
    "            results_list.append({'Name': name, \n",
    "                                'Method': folder.split('\\\\')[-1], \n",
    "                                'RV_HD': rv_hd, \n",
    "                                'MYO_HD': myo_hd, \n",
    "                                'LV_HD': lv_hd, \n",
    "                                'Mean_HD': (rv_hd + myo_hd + lv_hd) / 3,\n",
    "                                'RV_Dice': rv_dice,\n",
    "                                'MYO_Dice': myo_dice,\n",
    "                                'LV_Dice': lv_dice,\n",
    "                                'Mean Dice': (rv_dice + myo_dice + lv_dice) / 3})\n",
    "\n",
    "with open(os.path.join('Quorum_output_2', 'Quorum_methods_jmp.csv'), 'w') as fd_csv:\n",
    "    writer = csv.DictWriter(fd_csv, fieldnames=list(results_list[0].keys()))\n",
    "    writer.writeheader() \n",
    "    writer.writerows(results_list) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dice for 'temp_allClasses' folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import csv\n",
    "\n",
    "results_list = []\n",
    "with open(r'Quorum_output_2\\only_sfb\\fold_0\\temp_allClasses\\summary.json') as fd_json:\n",
    "    data = json.load(fd_json)\n",
    "    results = data['results']['all']\n",
    "    for res in results:\n",
    "        rv_dice = res['1']['Dice']\n",
    "        myo_dice = res['2']['Dice']\n",
    "        lv_dice = res['3']['Dice']\n",
    "        results_list.append({'RV': rv_dice, 'MYO': myo_dice, 'LV': lv_dice, 'Mean': (rv_dice + myo_dice + lv_dice) / 3})\n",
    "\n",
    "with open(os.path.join('Quorum_output_2\\only_sfb', 'Quorum_postprocess_allClasses_jmp.csv'), 'w') as fd_csv:\n",
    "    writer = csv.DictWriter(fd_csv, fieldnames=list(results_list[0].keys()))\n",
    "    writer.writeheader() \n",
    "    writer.writerows(results_list) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get images for worst predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from evaluation.metrics import dice\n",
    "import cv2 as cv\n",
    "\n",
    "h = 2\n",
    "w = int(round(h * (16/9)))\n",
    "\n",
    "name_list = []\n",
    "dice_list = []\n",
    "with open(os.path.join(r'Quorum_output_2\\all_data\\only_sfb\\temp_allClasses\\summary.json')) as fd_json:\n",
    "    data = json.load(fd_json)\n",
    "    results = data['results']['all']\n",
    "    for res in results:\n",
    "        name = res['reference'].split('\\\\')[-1]\n",
    "        rv_dice = res['1']['Dice']\n",
    "        myo_dice = res['2']['Dice']\n",
    "        lv_dice = res['3']['Dice']\n",
    "        mean = (rv_dice + myo_dice + lv_dice) / 3\n",
    "        name_list.append(name)\n",
    "        dice_list.append(mean)\n",
    "\n",
    "arr = np.stack([np.array(name_list), np.array(dice_list)], axis=0)\n",
    "indices = np.argsort(arr[1])\n",
    "arr = arr[:, indices]\n",
    "arr = arr[0, :h*w]\n",
    "path_array_pred = np.array(['Quorum_output_2\\\\all_data\\only_sfb\\\\temp_allClasses\\\\'])\n",
    "path_array_gt = np.array(['out\\\\nnUNet_raw_data_base\\\\nnUNet_raw_data\\Task029_Quorum\\labelsTr\\\\'])\n",
    "path_array_img = np.array(['out\\\\nnUNet_raw_data_base\\\\nnUNet_raw_data\\Task029_Quorum\\imagesTr\\\\'])\n",
    "pred_arr = np.char.add(path_array_pred, arr)\n",
    "gt_arr = np.char.add(path_array_gt, arr)\n",
    "img_arr = np.char.add(path_array_img, np.char.rstrip(arr, '.nii.gz'))\n",
    "img_arr = np.char.add(img_arr, np.array(['_0000.nii.gz']))\n",
    "\n",
    "fig, ax = plt.subplots(h, w)\n",
    "fig.tight_layout()\n",
    "fig.subplots_adjust(left=0.01, right=0.99, bottom=0.01, top=0.99, wspace=0.1, hspace=0.1)\n",
    "for idx, (prediction_path, gt_path, img_path) in enumerate(zip(pred_arr, gt_arr, img_arr)):\n",
    "    pred_data = nib.load(prediction_path)\n",
    "    pred_arr = pred_data.get_fdata()\n",
    "\n",
    "    gt_data = nib.load(gt_path)\n",
    "    gt_arr = gt_data.get_fdata()\n",
    "\n",
    "    img_data = nib.load(img_path)\n",
    "    img_arr = img_data.get_fdata()\n",
    "\n",
    "    score_list = []\n",
    "    for j in range(pred_arr.shape[-1]):\n",
    "        score = dice(pred_arr[:, :, j], gt_arr[:, :, j])\n",
    "        score_list.append(score)\n",
    "    score_list = np.array(score_list)\n",
    "    slice_nb = np.argmin(score_list)\n",
    "\n",
    "    img_arr = img_arr[:, :, slice_nb]\n",
    "    gt_arr = gt_arr[:, :, slice_nb]\n",
    "    pred_arr = pred_arr[:, :, slice_nb]\n",
    "\n",
    "    img_arr = cv.normalize(img_arr, None, alpha=0, beta=255, norm_type=cv.NORM_MINMAX).astype(np.uint8)\n",
    "    img_arr = cv.cvtColor(img_arr, cv.COLOR_GRAY2RGB)\n",
    "\n",
    "    for j in range(1, 4):\n",
    "        pred = (pred_arr == j).astype(np.uint8)\n",
    "        gt = (gt_arr == j).astype(np.uint8)\n",
    "        pred_contours, hierarchy = cv.findContours(pred, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        gt_contours, hierarchy = cv.findContours(gt, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        pred_color = [255, 0, 0]\n",
    "        gt_color = [0, 255, 0]\n",
    "        img_arr = cv.drawContours(img_arr, pred_contours, -1, pred_color, 1)\n",
    "        img_arr = cv.drawContours(img_arr, gt_contours, -1, gt_color, 1)\n",
    "\n",
    "    ax[int(idx//w), int(idx%w)].imshow(img_arr)\n",
    "    ax[int(idx//w), int(idx%w)].set_axis_off()\n",
    "\n",
    "plt.savefig(\"squares.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23812/590206307.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0max\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_gt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitforbuttonpress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mwaitforbuttonpress\u001b[1;34m(timeout)\u001b[0m\n\u001b[0;32m   2306\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_copy_docstring_and_deprecators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitforbuttonpress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2307\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mwaitforbuttonpress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2308\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitforbuttonpress\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2310\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mwaitforbuttonpress\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   3123\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3124\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3125\u001b[1;33m         _blocking_input.blocking_input_loop(\n\u001b[0m\u001b[0;32m   3126\u001b[0m             self, [\"button_press_event\", \"key_press_event\"], timeout, handler)\n\u001b[0;32m   3127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\_blocking_input.py\u001b[0m in \u001b[0;36mblocking_input_loop\u001b[1;34m(figure, event_names, timeout, handler)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mcids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmpl_connect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandler\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mevent_names\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Start event loop.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Run even on exception like ctrl-c.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[1;31m# Disconnect the callbacks.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\backends\\backend_qt.py\u001b[0m in \u001b[0;36mstart_event_loop\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    407\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0m_maybe_allow_interrupt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_loop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 409\u001b[1;33m             \u001b[0mqt_compat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_exec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevent_loop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    410\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstop_event_loop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevent\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m    122\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 124\u001b[1;33m                 \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    125\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    126\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Portal\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\matplotlib\\backends\\qt_compat.py\u001b[0m in \u001b[0;36m_maybe_allow_interrupt\u001b[1;34m(qapp)\u001b[0m\n\u001b[0;32m    260\u001b[0m             \u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSIGINT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mold_sigint_handler\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhandler_args\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m                 \u001b[0mold_sigint_handler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mhandler_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "data = nib.load(r'out\\nnUNet_raw_data_base\\nnUNet_raw_data\\Task029_Quorum\\imagesTr\\patient082_ed_0000.nii.gz')\n",
    "arr = data.get_fdata()\n",
    "\n",
    "data_gt = nib.load(r'out\\nnUNet_raw_data_base\\nnUNet_raw_data\\Task029_Quorum\\labelsTr\\patient082_ed.nii.gz')\n",
    "arr_gt = data_gt.get_fdata()\n",
    "\n",
    "for i in range(arr.shape[-1]):\n",
    "    fig, ax = plt.subplots(1, 2)\n",
    "    ax[0].imshow(arr[:, :, i], cmap='gray')\n",
    "    ax[1].imshow(arr_gt[:, :, i], cmap='gray')\n",
    "    plt.waitforbuttonpress()\n",
    "    plt.show()\n",
    "    plt.close(fig)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get number of centers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['250001' '250005' '276004' '276005' '276006' '276007' '276008' '348001'\n",
      " '348002' '348003' '348004' '348007' '616003' '616005' '616006' '616009'\n",
      " '616010' '616012' '703001' '703003' '703004' '724002' '724005' '724006']\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "center_list = []\n",
    "path_list = glob(r'data_saud_2\\3D\\**\\*.csv', recursive=True)\n",
    "for path in path_list:\n",
    "    df = pd.read_csv(path)\n",
    "    center = df['Name'][0].split('-')[0]\n",
    "    center_list.append(center)\n",
    "center_list = np.array(center_list)\n",
    "out = np.unique(center_list)\n",
    "print(out)\n",
    "print(out.size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dice per depth level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Portal\\AppData\\Local\\Temp/ipykernel_14516/501963590.py:68: RuntimeWarning: Mean of empty slice\n",
      "  class_dice = np.nanmean(class_dice, axis=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84526021 0.87585766 0.92302147]\n"
     ]
    }
   ],
   "source": [
    "from evaluation.metrics import dice\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "from glob import glob\n",
    "import math\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "path_list = glob(r'Quorum_output_2\\all_data\\only_sfb\\temp_allClasses\\*.gz')\n",
    "path_list_names = [x.split('\\\\')[-1][:13] for x in path_list]\n",
    "path_list_gt = glob(r'custom_quorum\\**\\*_gt.nii.gz', recursive=True)\n",
    "path_list_gt = [x for x in path_list_gt if x.split('\\\\')[-1][:13] in path_list_names]\n",
    "assert len(path_list_gt) == len(path_list)\n",
    "\n",
    "path_list = sorted(path_list, key=lambda x:x.split('\\\\')[-1])\n",
    "path_list_gt = sorted(path_list_gt, key=lambda x:x.split('\\\\')[-1])\n",
    "\n",
    "out_dict = {}\n",
    "scores = []\n",
    "for path, path_gt in zip(path_list, path_list_gt):\n",
    "    data = nib.load(path)\n",
    "    arr = data.get_fdata()\n",
    "\n",
    "    data_gt = nib.load(path_gt)\n",
    "    arr_gt = data_gt.get_fdata()\n",
    "\n",
    "    assert arr.shape == arr_gt.shape\n",
    "    patient_scores = []\n",
    "    for i in range(arr.shape[-1]):\n",
    "        #fig, ax = plt.subplots(1, 2)\n",
    "        #ax[0].imshow(arr[:, :, i], cmap='gray')\n",
    "        #ax[1].imshow(arr_gt[:, :, i], cmap='gray')\n",
    "        #plt.show()\n",
    "        #plt.waitforbuttonpress()\n",
    "        #plt.close(fig)\n",
    "\n",
    "        current_pred = arr[:, :, i]\n",
    "        current_gt = arr_gt[:, :, i]\n",
    "\n",
    "        #current_pred = arr\n",
    "        #current_gt = arr_gt\n",
    "\n",
    "        class_score = []\n",
    "        for j in range(1, 4):\n",
    "            current_class_pred = current_pred == j\n",
    "            current_gt_pred = current_gt == j\n",
    "            score = dice(current_class_pred, current_gt_pred)\n",
    "            class_score.append(score)\n",
    "        out_dict = update_dict(out_dict, key=i/arr.shape[-1], value=np.array(class_score))\n",
    "        patient_scores.append(np.array(class_score))\n",
    "    patient_class_score = np.stack(patient_scores, axis=0)\n",
    "    patient_class_score = np.nanmean(patient_class_score, axis=0)\n",
    "    scores.append(patient_class_score)\n",
    "scores = np.stack(scores, 0)\n",
    "scores = np.nanmean(scores, axis=0)\n",
    "\n",
    "x = [[], [], []]\n",
    "y = [[], [], []]\n",
    "for key in out_dict.keys():\n",
    "    class_dice = np.stack(out_dict[key], axis=0)\n",
    "    class_dice = np.nanmean(class_dice, axis=0)\n",
    "    for i in range(3):\n",
    "        if not math.isnan(class_dice[i]):\n",
    "            x[i].append(key)\n",
    "            y[i].append(class_dice[i])\n",
    "\n",
    "print(np.array(scores))\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(np.array(x[0]), np.array(y[0]), c='r', label='RV')\n",
    "ax.scatter(np.array(x[1]), np.array(y[1]), c='g', label='MYO')\n",
    "ax.scatter(np.array(x[2]), np.array(y[2]), c='b', label='LV')\n",
    "ax.set(xlabel='Depth as percent of volume', ylabel='Dice score')\n",
    "ax.legend()\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de6e7f1d27ee98e0dd03d720850162ba8f013030d5557c31bd8d79f8fd588abc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
