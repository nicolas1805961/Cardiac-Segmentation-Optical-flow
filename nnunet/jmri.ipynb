{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get results by criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import yaml\n",
    "import pandas as pd\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "output_file_name = 'quorum_output_file.yaml'\n",
    "if os.path.exists(output_file_name):\n",
    "    os.remove(output_file_name)\n",
    "\n",
    "centers = {}\n",
    "manufacturers = {}\n",
    "strengths = {}\n",
    "depths = {}\n",
    "phases = {}\n",
    "\n",
    "path_list = glob(r'quorum_output_2\\temp_allClasses\\*.gz')\n",
    "for path in path_list:\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    name = filename.split('_')[0]\n",
    "    df = pd.read_csv(os.path.join('custom_quorum_2', name, phase + '_info.csv'))\n",
    "    center = df['Name'].iloc[0].split('-')[0]\n",
    "    manufacturer = df['Manufacturer'].iloc[0]\n",
    "    strength = df['Field Strength'].iloc[0]\n",
    "\n",
    "    centers = update_dict(centers, str(center), filename)\n",
    "    manufacturers = update_dict(manufacturers, str(manufacturer), filename)\n",
    "    strengths = update_dict(strengths, str(strength), filename)\n",
    "    phases = update_dict(phases, str(phase), filename)\n",
    "\n",
    "with open(r'quorum_output_2\\temp_allClasses\\summary.json', 'r') as fd_in:\n",
    "    metric_file = json.load(fd_in)['results']['all']\n",
    "    results_dict = {}\n",
    "    for current_dict in [centers, manufacturers, strengths, phases]:\n",
    "        for key in current_dict.keys():\n",
    "            current_values = current_dict[key]\n",
    "            list_of_dict = [x for x in metric_file if x['reference'].split('/')[-1] in current_values]\n",
    "            mean_dice_list = []\n",
    "            mean_hausdorff_list = []\n",
    "            for data_dict in list_of_dict:\n",
    "                mean_dice_list.append([data_dict['1']['Dice'], data_dict['2']['Dice'], data_dict['3']['Dice']])\n",
    "                mean_hausdorff_list.append([data_dict['1']['Hausdorff Distance'], data_dict['2']['Hausdorff Distance'], data_dict['3']['Hausdorff Distance']])\n",
    "            class_dice = np.stack(mean_dice_list, axis=0).mean(axis=0)\n",
    "            class_hausdorff = np.stack(mean_hausdorff_list, axis=0).mean(axis=0)\n",
    "            results_dict[key] = {'Hausdorff distance': class_hausdorff.tolist(), \n",
    "                                'Mean Hausdorff distance': float(class_hausdorff.mean()), \n",
    "                                'Dice score': class_dice.tolist(),\n",
    "                                'Mean dice score': float(class_dice.mean())}\n",
    "\n",
    "with open(output_file_name, 'w') as fd:\n",
    "    yaml.safe_dump(results_dict, fd, default_flow_style=False)\n",
    "    #for results_dict in results_dicts:\n",
    "    #    for key in results_dict.keys():\n",
    "    #        fd.write(key + ': ' + str(results_dict[key]) + '\\n')\n",
    "    #    fd.write('\\n')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get ED/ES volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13.234375\n",
      "187504.625\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "data = nib.load(r'quorum_output\\validation_raw\\patient003_ed.nii.gz')\n",
    "zoom = data.header.get_zooms()\n",
    "pixel_volume = np.prod(zoom)\n",
    "print(pixel_volume)\n",
    "arr = data.get_fdata()\n",
    "nb_pixels = np.count_nonzero(arr == 1)\n",
    "print(nb_pixels * pixel_volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(288, 288, 13)\n",
      "(288, 288, 14)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage import distance_transform_edt\n",
    "from scipy.interpolate import interpn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bwperim(bw, n=4):\n",
    "    \"\"\"\n",
    "    perim = bwperim(bw, n=4)\n",
    "    Find the perimeter of objects in binary images.\n",
    "    A pixel is part of an object perimeter if its value is one and there\n",
    "    is at least one zero-valued pixel in its neighborhood.\n",
    "    By default the neighborhood of a pixel is 4 nearest pixels, but\n",
    "    if `n` is set to 8 the 8 nearest pixels will be considered.\n",
    "    Parameters\n",
    "    ----------\n",
    "      bw : A black-and-white image\n",
    "      n : Connectivity. Must be 4 or 8 (default: 8)\n",
    "    Returns\n",
    "    -------\n",
    "      perim : A boolean image\n",
    "    \"\"\"\n",
    "\n",
    "    if n not in (4,8):\n",
    "        raise ValueError('mahotas.bwperim: n must be 4 or 8')\n",
    "    rows,cols = bw.shape\n",
    "\n",
    "    # Translate image by one pixel in all directions\n",
    "    north = np.zeros((rows,cols))\n",
    "    south = np.zeros((rows,cols))\n",
    "    west = np.zeros((rows,cols))\n",
    "    east = np.zeros((rows,cols))\n",
    "\n",
    "    north[:-1,:] = bw[1:,:]\n",
    "    south[1:,:]  = bw[:-1,:]\n",
    "    west[:,:-1]  = bw[:,1:]\n",
    "    east[:,1:]   = bw[:,:-1]\n",
    "    idx = (north == bw) & \\\n",
    "          (south == bw) & \\\n",
    "          (west  == bw) & \\\n",
    "          (east  == bw)\n",
    "    if n == 8:\n",
    "        north_east = np.zeros((rows, cols))\n",
    "        north_west = np.zeros((rows, cols))\n",
    "        south_east = np.zeros((rows, cols))\n",
    "        south_west = np.zeros((rows, cols))\n",
    "        north_east[:-1, 1:]   = bw[1:, :-1]\n",
    "        north_west[:-1, :-1] = bw[1:, 1:]\n",
    "        south_east[1:, 1:]     = bw[:-1, :-1]\n",
    "        south_west[1:, :-1]   = bw[:-1, 1:]\n",
    "        idx &= (north_east == bw) & \\\n",
    "               (south_east == bw) & \\\n",
    "               (south_west == bw) & \\\n",
    "               (north_west == bw)\n",
    "    return ~idx * bw\n",
    "\n",
    "def signed_bwdist(im):\n",
    "    '''\n",
    "    Find perim and return masked image (signed/reversed)\n",
    "    '''    \n",
    "    perimeter = bwperim(im)\n",
    "    distance_map = bwdist(perimeter)\n",
    "    im = -distance_map*np.logical_not(im) + distance_map*im\n",
    "    return im\n",
    "\n",
    "def bwdist(im):\n",
    "    '''\n",
    "    Find distance map of image\n",
    "    '''\n",
    "    dist_im = distance_transform_edt(1-im)\n",
    "    return dist_im\n",
    "\n",
    "def interp_shape(arr, new_depth):\n",
    "    '''\n",
    "    Interpolate between two contours\n",
    "\n",
    "    Input: top \n",
    "            [X,Y] - Image of top contour (mask)\n",
    "           bottom\n",
    "            [X,Y] - Image of bottom contour (mask)\n",
    "           precision\n",
    "             float  - % between the images to interpolate \n",
    "                Ex: num=0.5 - Interpolate the middle image between top and bottom image\n",
    "    Output: out\n",
    "            [X,Y] - Interpolated image at num (%) between top and bottom\n",
    "\n",
    "    '''\n",
    "    X, Y, Z = arr.shape\n",
    "\n",
    "    distance_arr = []\n",
    "    for i in range(Z):\n",
    "        distance_arr.append(signed_bwdist(arr[:, :, i]))\n",
    "    distance_arr = np.stack(distance_arr, axis=-1)\n",
    "\n",
    "    x = np.arange(0, X)\n",
    "    y = np.arange(0, Y)\n",
    "    z = np.arange(0, Z)\n",
    "    points = (x, y, z)\n",
    "\n",
    "    stop = Z-1\n",
    "\n",
    "    # create ndgrids\n",
    "    grid = np.mgrid[:X, :Y, 0:stop:(new_depth * 1j)]\n",
    "    xi = np.rollaxis(grid, 0, 4)\n",
    "    xi = xi.reshape((X * Y * new_depth, 3))\n",
    "\n",
    "    out = interpn(points, arr, xi)\n",
    "    out = out.reshape((X, Y, new_depth))\n",
    "\n",
    "    # Threshold distmap to values above 0\n",
    "    out = out > 0\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "data = nib.load(r'quorum_output\\validation_raw\\patient003_ed.nii.gz')\n",
    "arr = data.get_fdata()\n",
    "arr = arr == 1\n",
    "\n",
    "X, Y, Z = arr.shape\n",
    "print(arr.shape)\n",
    "# Run interpolation\n",
    "out = interp_shape(arr, Z+1)\n",
    "print(out.shape)\n",
    "#fig, ax = plt.subplots(1, Z+1)\n",
    "#for i in range(Z+1):\n",
    "#    ax[i].imshow(out[:, :, i], cmap='gray')\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:27<00:00, 29.26s/it]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib qt\n",
    "\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "path_list = glob(r'quorum_output_2\\temp_allClasses\\*.gz')\n",
    "ed_path_list = []\n",
    "es_path_list = []\n",
    "ed_spacing = []\n",
    "es_spacing = []\n",
    "for path in path_list:\n",
    "    filename = path.split('\\\\')[-1]\n",
    "    phase = filename[11:13]\n",
    "    name = filename.split('_')[0]\n",
    "    df = pd.read_csv(os.path.join('custom_quorum_2', name, phase + '_info.csv'))\n",
    "    spacing = (df['Space Between Slices'] - df['Slice Thickness']).to_numpy()[0]\n",
    "    if phase == 'ed':\n",
    "        ed_path_list.append(path)\n",
    "        ed_spacing.append(spacing)\n",
    "    elif phase == 'es':\n",
    "        es_path_list.append(path)\n",
    "        es_spacing.append(spacing)\n",
    "\n",
    "#ed_path_list = [x for x in path_list if '_ed.' in x]\n",
    "#es_path_list = [x for x in path_list if '_es.' in x]\n",
    "\n",
    "results = {}\n",
    "for i, class_name in enumerate(tqdm(['RV', 'MYO', 'LV']), 1):\n",
    "    ed_volume_list = []\n",
    "    ed_volume_list_interp = []\n",
    "    for ed_path, spacing in zip(ed_path_list, ed_spacing):\n",
    "        data = nib.load(ed_path)\n",
    "        zoom = list(data.header.get_zooms())\n",
    "        arr = data.get_fdata()\n",
    "        pixel_size = np.prod(zoom)\n",
    "\n",
    "        new_depth = round((spacing * (arr.shape[-1] - 1)) / zoom[-1]) + arr.shape[-1]\n",
    "        #print(arr.shape[-1])\n",
    "        #print(new_depth)\n",
    "        #print('******************************')\n",
    "\n",
    "        class_nb_pixels = arr == i\n",
    "\n",
    "        ed_volume_list.append(pixel_size * class_nb_pixels.sum())\n",
    "        arr_interpolated = interp_shape(class_nb_pixels, new_depth)\n",
    "        ed_volume_list_interp.append(pixel_size * arr_interpolated.sum())\n",
    "\n",
    "    mean_ed_volume = float(np.array(ed_volume_list).mean() / 1000)\n",
    "    mean_ed_volume_interp = float(np.array(ed_volume_list_interp).mean() / 1000)\n",
    "\n",
    "    es_volume_list = []\n",
    "    es_volume_list_interp = []\n",
    "    for es_path, spacing in zip(es_path_list, es_spacing):\n",
    "        data = nib.load(es_path)\n",
    "        zoom = list(data.header.get_zooms())\n",
    "        arr = data.get_fdata()\n",
    "        pixel_size = np.prod(zoom) #cm3\n",
    "\n",
    "        new_depth = round((spacing * (arr.shape[-1] - 1)) / zoom[-1]) + arr.shape[-1]\n",
    "\n",
    "        class_nb_pixels = arr == i\n",
    "\n",
    "        es_volume_list.append(pixel_size * class_nb_pixels.sum())\n",
    "        arr_interpolated = interp_shape(class_nb_pixels, new_depth)\n",
    "        es_volume_list_interp.append(pixel_size * arr_interpolated.sum())\n",
    "\n",
    "    mean_es_volume = float(np.array(es_volume_list).mean() / 1000)\n",
    "    mean_es_volume_interp = float(np.array(es_volume_list_interp).mean() / 1000)\n",
    "\n",
    "    results[class_name] = {'ED': {'volume': mean_ed_volume, 'interpolated_volume': mean_ed_volume_interp},\n",
    "                            'ES': {'volume': mean_es_volume, 'interpolated_volume': mean_es_volume_interp}}\n",
    "    if class_name != 'MYO':\n",
    "        results[class_name].update({'Fraction d\\'ejection': {'no_interpolation': ((mean_ed_volume - mean_es_volume) / mean_ed_volume) * 100, 'interpolated': ((mean_ed_volume_interp - mean_es_volume_interp) / mean_ed_volume_interp) * 100},\n",
    "                                    'Volume d\\'ejection': {'no_interpolation': (mean_ed_volume - mean_es_volume), 'interpolated': (mean_ed_volume_interp - mean_es_volume_interp)}})\n",
    "                            \n",
    "\n",
    "with open(output_file_name, 'r') as fd:\n",
    "    my_dict = yaml.safe_load(fd)\n",
    "    my_dict.update(results)\n",
    "with open(output_file_name, 'w') as fd:\n",
    "    yaml.safe_dump(my_dict, fd, default_flow_style=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get dice per depth level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation.metrics import dice\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "\n",
    "def update_dict(d, key, value):\n",
    "    if key not in d:\n",
    "        d[key] = [value]\n",
    "    else:\n",
    "        d[key].append(value)\n",
    "    return d\n",
    "\n",
    "path_list = glob(r'quorum_output_2\\temp_allClasses\\*.gz')\n",
    "path_list_names = [x.split('\\\\')[-1][:13] for x in path_list]\n",
    "path_list_gt = glob(r'custom_quorum_2\\**\\*_gt.nii.gz', recursive=True)\n",
    "path_list_gt = [x for x in path_list_gt if x.split('\\\\')[-1][:13] in path_list_names]\n",
    "assert len(path_list_gt) == len(path_list)\n",
    "\n",
    "path_list = sorted(path_list, key=lambda x:x.split('\\\\')[-1])\n",
    "path_list_gt = sorted(path_list_gt, key=lambda x:x.split('\\\\')[-1])\n",
    "\n",
    "\n",
    "out_dict = {}\n",
    "for path, path_gt in zip(path_list, path_list_gt):\n",
    "    data = nib.load(path)\n",
    "    arr = data.get_fdata()\n",
    "\n",
    "    data_gt = nib.load(path_gt)\n",
    "    arr_gt = data_gt.get_fdata()\n",
    "\n",
    "    assert arr.shape == arr_gt.shape\n",
    "    for i in range(arr.shape[-1]):\n",
    "        #fig, ax = plt.subplots(1, 2)\n",
    "        #ax[0].imshow(arr[:, :, i], cmap='gray')\n",
    "        #ax[1].imshow(arr_gt[:, :, i], cmap='gray')\n",
    "        #plt.show()\n",
    "        #plt.waitforbuttonpress()\n",
    "        #plt.close(fig)\n",
    "        score = dice(test=arr[:, :, i], reference=arr_gt[:, :, i])\n",
    "        out_dict = update_dict(out_dict, key=i/arr.shape[-1], value=score)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for key in out_dict.keys():\n",
    "    x.append(key)\n",
    "    y.append(np.array(out_dict[key]).mean())\n",
    "\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "ax.scatter(np.array(x), np.array(y))\n",
    "ax.set(xlabel='Depth as percent of volume', ylabel='Dice score')\n",
    "ax.xaxis.set_major_formatter(mtick.PercentFormatter(1.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "de6e7f1d27ee98e0dd03d720850162ba8f013030d5557c31bd8d79f8fd588abc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
