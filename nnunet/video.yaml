model: 'swin' #'swin'
separability: False
separability_loss_weight: 1.0
convolutional_patch_embedding: True

#labeled_segmentation_weight: 0.1
#unlabeled_segmentation_weight: 0.1
#strong_network_lr: 0.0001
#strong_network_decay: 0.0001

seg_registered_target_loss_weight: 1.0
seg_registered_pred_loss_weight: 1.0
pred_registered_pred_loss_weight: 0.0
pred_registered_target_loss_weight: 0.0

bidirectional: False
blackout_percent: 0.0
all_to_all: True
one_to_all: False
inference_mode: one_step # sliding_window, one_step, overlap
temporal_kernel_size: 8
load_only_batchnorm: False
consistency_loss_weight: 0.0 #0.01
regularization_weight_xy: 0.0 #0.01
regularization_weight_z: 0.0 #0.01
dot_multiplier: 2
nb_tokens: 8
segmentation_loss_weight: 1.0 # 1.0
image_flow_loss_weight: 0.0 # 0.0
long_image_flow_loss_weight: 0.0 # 0.0
force_one_label: True
feature_extractor: False
video_length: 2
crop: True
cropper_weights_folder_path: 'binary'
video_weights_folder_path: 'pretrained'
crop_size: 128
nb_layers: 1

unlabeled: False
log_images: True
patch_size: [224, 224]
device: 'cuda:0'
deep_supervision: False
epoch_log: 1 #10
scheduler: 'cosine'
optimizer: 'adam'
initial_lr: 0.0001 #0.0001
weight_decay: 0.0001 #0.0001
warmup_percent: 0.1
max_num_epochs: 200 #400
#window_size: 7
#image_size: 224
norm: 'batchnorm' # 'instancenorm', 'batchnorm'
bottleneck_heads: 8 # 16
activation: 'gelu'
conv_layer: 'other'
dropout: 0
conv_depth: [2, 2, 2]
transformer_depth: [] #[2, 2, 2], [2]
num_heads: [] #[3, 6, 12], [8] [12]
spatial_cross_attention_num_heads: [8, 8, 8] #[2, 4, 6, 8, 12] [12, 8, 6, 4, 2] [bottom, ..., top] [3, 6, 12] [4, 4, 8, 8, 16]
batch_size: 3 #16
drop_path_rate: 0.0
in_encoder_dims: [1, 128, 256] #[1, 24, 96, 192, 384] [1, 96, 384] [1, 24, 96] [1, 32, 128] [1, 32, 128, 256, 512] [1, 48, 192] [1, 96, 192]
out_encoder_dims: [64, 128, 256] #[24, 48, 96, 192, 384] [96, 192, 384] [24, 48, 96] [32, 64, 128] [32, 64, 128, 256, 512] [48, 96, 192] [96, 192, 384]
loss: 'ce_and_dice' # ['ce_and_dice', 'focal_and_dice', 'topk_and_dice', 'ce']

do_adv: False
adversarial_weight: 0.0
discriminator_depth: [2, 2, 2]
discriminator_in_dims: [4, 128, 256]
discriminator_out_dims: [64, 128, 256]
discriminator_lr: 0.00001 # 0.00005
discriminator_decay: 0.0001

reinforcement: False
policy_net_learning_rate: 0.0001
number_of_intervals: 20
number_of_steps: 200
